1. Otazka: Pop√≠≈°te proces z√≠skavania digit√°lneho obrazu: model dierkovej kamery, transform√°cie z 3D do 2D, ƒço je obrazov√° funkcia, ak√Ω je rozdiel medzi spojitou a diskr√©tnou (digit√°lnou) obrazovou funkciou, vzorkovanie, kvantiz√°cia, aliasing a s√∫vis so Shanonovou teor√©mou, z√≠skanie farebn√©ho obrazu a demozaikovanie, prevod farebn√©ho obrazu na ≈°edot√≥nov√Ω.

1. Model dierkovej kamery (pinhole camera)
- Najjednoduch≈°√≠ model zobrazenia 3D sc√©ny na 2D plochu
- Svetlo prech√°dza mal√Ωm otvorom (dierkou) a premieta sa na zadn√∫ stenu
- Matematick√Ω model:
```
x' = f * (X/Z)
y' = f * (Y/Z)
```
kde (X,Y,Z) s√∫ s√∫radnice 3D bodu a (x',y') s√∫ s√∫radnice jeho projekcie na obrazov√∫ rovinu, f je ohniskov√° vzdialenos≈•

2. Transform√°cia z 3D do 2D
- Perspekt√≠vna projekcia: objekty ƒèalej od kamery sa javia men≈°ie
- Homog√©nne s√∫radnice: pou≈æ√≠vaj√∫ sa na zjednodu≈°enie v√Ωpoƒçtov
- Projekƒçn√° matica:
```
[f 0 0  0]
[0 f 0  0]
[0 0 1  0]
```

3. Obrazov√° funkcia
- Spojit√° obrazov√° funkcia f(x,y): 
  - Definuje intenzitu/jas v ka≈ædom bode obrazu
  - (x,y) s√∫ priestorov√© s√∫radnice
  - Hodnota funkcie predstavuje jas alebo intenzitu v danom bode
  
- Diskr√©tna obrazov√° funkcia f[m,n]:
  - Vznik√° vzorkovan√≠m spojitej funkcie
  - [m,n] s√∫ diskr√©tne s√∫radnice (cel√© ƒç√≠sla)
  - Hodnoty s√∫ kvantovan√© do koneƒçn√©ho poƒçtu √∫rovn√≠

4. Vzorkovanie a kvantiz√°cia
- Vzorkovanie:
  - Prevod spojit√©ho sign√°lu na diskr√©tny
  - Vzorkovacia frekvencia mus√≠ spƒ∫≈àa≈• Shannonov teor√©m
  - Pr√≠klad vzorkovania:
```
Pre obrazov√Ω sign√°l s maxim√°lnou frekvenciou fmax = 100 Hz
Potrebn√° vzorkovacia frekvencia: fs > 2 * fmax = 200 Hz
```

- Kvantiz√°cia:
  - Prevod spojit√Ωch hodn√¥t na diskr√©tne √∫rovne
  - Typicky 8 bitov = 256 √∫rovn√≠ pre ≈°edot√≥nov√Ω obraz
  - Pr√≠klad:
```
Hodnota 127.3 -> 127
Hodnota 127.7 -> 128
```

5. Aliasing a Shannonov teor√©m
- Aliasing:
  - Vznik√° pri nedostatoƒçnej vzorkovacej frekvencii
  - Prejavuje sa ako "schodovit√Ω efekt" na hran√°ch
  - Rie≈°enie: anti-aliasing filter pred vzorkovan√≠m

- Shannonov teor√©m:
  - fs > 2 * fmax
  - Vzorkovacia frekvencia mus√≠ by≈• aspo≈à 2-kr√°t vy≈°≈°ia ako najvy≈°≈°ia frekvencia v sign√°li

6. Z√≠skanie farebn√©ho obrazu a demozaikovanie
- Bayerova maska:
  - RGGB vzor filtrov na senzore
  - 50% zelen√Ωch, 25% ƒçerven√Ωch, 25% modr√Ωch pixelov
  - Pr√≠klad rozlo≈æenia:
```
R G R G
G B G B
R G R G
G B G B
```

- Demozaikovanie:
  - Interpol√°cia ch√Ωbaj√∫cich farebn√Ωch hodn√¥t
  - Met√≥dy: biline√°rna interpol√°cia, adapt√≠vne met√≥dy
  - Pr√≠klad biline√°rnej interpol√°cie pre ƒçerven√Ω kan√°l v zelenom pixeli:
```
R = (R1 + R2) / 2
kde R1, R2 s√∫ susedn√© ƒçerven√© pixely
```

7. Prevod farebn√©ho obrazu na ≈°edot√≥nov√Ω
- V√°≈æen√Ω s√∫ƒçet RGB kan√°lov:
```
Y = 0.299*R + 0.587*G + 0.114*B
```
- V√°hy zodpovedaj√∫ citlivosti ƒæudsk√©ho oka na jednotliv√© farby

Praktick√© pr√≠klady:
1. V√Ωpoƒçet rozl√≠≈°enia potrebn√©ho pre zachytenie detailov:
```
Ak chceme zachyti≈• detaily veƒækosti 1mm z vzdialenosti 1m:
- Pou≈æijeme vztah: rozl√≠≈°enie = (2 * œÄ * vzdialenos≈•) / veƒækos≈•_detailu
- rozl√≠≈°enie = (2 * œÄ * 1000mm) / 1mm ‚âà 6283 pixelov
```

2. V√Ωpoƒçet veƒækosti s√∫boru:
```
Pre 8-megapixelov√Ω farebn√Ω obraz (RGB):
- 8,000,000 pixelov * 3 kan√°ly * 8 bitov = 192,000,000 bitov
- 192,000,000 / 8 = 24,000,000 bajtov = pribli≈æne 24 MB
```

T√°to l√°tka je z√°kladom pre pochopenie digit√°lneho spracovania obrazu. Pri ≈°t√∫diu sa zamerajte najm√§ na:
- Pochopenie vz≈•ahu medzi spojit√Ωm a diskr√©tnym obrazom
- V√Ωznam vzorkovacej frekvencie a Shannonovho teor√©mu
- Princ√≠py farebn√©ho sn√≠mania a spracovania obrazu

2. Otazka: Fundament√°lna matica kamery, jej rozklad na vonkaj≈°iu a vn√∫torn√∫ maticu, ƒço popisuj√∫ jednotliv√© matice, princ√≠p procesu kalibr√°cie kamery, ƒço je reprojekƒçn√° chyba, skreslenie - radi√°lne a tangeci√°lne

Priprav√≠m pre v√°s podrobn√Ω popis fundament√°lnej matice kamery a procesu kalibr√°cie.

1. Fundament√°lna matica kamery (P)
- Je 3√ó4 projekƒçn√° matica, ktor√° transformuje 3D body na 2D obrazov√© body
- Zah≈ï≈àa v≈°etky parametre kamery (vn√∫torn√© aj vonkaj≈°ie)
- Matematick√Ω z√°pis:
```
P = K[R|t]
kde:
P - fundament√°lna matica (3√ó4)
K - vn√∫torn√° matica (3√ó3)
[R|t] - vonkaj≈°ia matica (3√ó4)
```

2. Rozklad na matice:

a) Vn√∫torn√° matica (K):
```
K = [fx  s  cx]
    [0   fy cy]
    [0   0   1]

kde:
fx, fy - ohniskov√© vzdialenosti v pixeloch
cx, cy - s√∫radnice hlavn√©ho bodu (principal point)
s - skew parameter (v√§ƒç≈°inou 0)
```
- Popisuje vn√∫torn√© parametre kamery
- Transformuje normalizovan√© s√∫radnice na pixelov√© s√∫radnice
- Nez√°vis√≠ od polohy kamery v priestore

b) Vonkaj≈°ia matica [R|t]:
```
[R|t] = [r11 r12 r13 t1]
        [r21 r22 r23 t2]
        [r31 r32 r33 t3]

kde:
R - rotaƒçn√° matica 3√ó3
t - translaƒçn√Ω vektor 3√ó1
```
- Popisuje polohu a orient√°ciu kamery v priestore
- R - rot√°cia kamery
- t - posun kamery vzhƒæadom na svetov√Ω s√∫radnicov√Ω syst√©m

3. Kalibr√°cia kamery:

a) Proces kalibr√°cie:
1. Z√≠skanie kalibraƒçn√Ωch sn√≠mok:
   - Pou≈æitie kalibraƒçn√©ho vzoru (≈°achovnica)
   - Zachytenie vzoru z r√¥znych uhlov a vzdialenost√≠

2. Detekcia v√Ωznaƒçn√Ωch bodov:
   - N√°jdenie rohov ≈°achovnice
   - Urƒçenie ich presnej poz√≠cie v pixeloch

3. Rie≈°enie s√∫stavy rovn√≠c:
```
Pre ka≈æd√Ω bod:
x' = PX
kde:
x' - 2D bod v obraze
X - 3D bod v priestore
P - hƒæadan√° fundament√°lna matica
```

4. Reprojekƒçn√° chyba:
- Miera presnosti kalibr√°cie
- Vypoƒç√≠ta sa ako:
```
E = Œ£ ||xi' - P*Xi||¬≤
kde:
xi' - skutoƒçn√° poz√≠cia bodu v obraze
P*Xi - prepoƒç√≠tan√° poz√≠cia 3D bodu do obrazu
```
- ƒå√≠m men≈°ia chyba, t√Ωm presnej≈°ia kalibr√°cia
- Typick√© hodnoty: 0.1 - 1.0 pixela

5. Skreslenie obrazu:

a) Radi√°lne skreslenie:
- Sp√¥sobuje "s√∫dkovitos≈•" alebo "podu≈°kovitos≈•" obrazu
- Modeluje sa polyn√≥mom:
```
x_distorted = x(1 + k1*r¬≤ + k2*r‚Å¥ + k3*r‚Å∂)
y_distorted = y(1 + k1*r¬≤ + k2*r‚Å¥ + k3*r‚Å∂)

kde:
r¬≤ = x¬≤ + y¬≤
k1, k2, k3 - koeficienty radi√°lneho skreslenia
```

b) Tangenci√°lne skreslenie:
- Vznik√° pri nedokonalom zarovnan√≠ ≈°o≈°oviek
- Matematick√Ω model:
```
x_distorted = x + [2p1xy + p2(r¬≤ + 2x¬≤)]
y_distorted = y + [p1(r¬≤ + 2y¬≤) + 2p2xy]

kde:
p1, p2 - koeficienty tangenci√°lneho skreslenia
```

Praktick√Ω pr√≠klad kalibr√°cie:
```python
# OpenCV pr√≠klad kalibr√°cie
import cv2
import numpy as np

# Pr√≠prava bodov ≈°achovnice
objp = np.zeros((6*7,3), np.float32)
objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)

# Zber bodov z viacer√Ωch sn√≠mok
objpoints = [] # 3D body v re√°lnom priestore
imgpoints = [] # 2D body v obraze

# Pre ka≈æd√∫ kalibraƒçn√∫ sn√≠mku
ret, corners = cv2.findChessboardCorners(gray, (7,6), None)
if ret:
    objpoints.append(objp)
    imgpoints.append(corners)

# Kalibr√°cia
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    objpoints, imgpoints, gray.shape[::-1], None, None)
```

D√¥le≈æit√© body na zapam√§tanie:
1. Fundament√°lna matica P kombinuje vn√∫torn√© a vonkaj≈°ie parametre kamery
2. Vn√∫torn√° matica K popisuje vlastnosti samotnej kamery
3. Vonkaj≈°ia matica [R|t] popisuje polohu kamery v priestore
4. Kalibr√°cia je proces urƒçenia v≈°etk√Ωch t√Ωchto parametrov
5. Reprojekƒçn√° chyba sl√∫≈æi na overenie kvality kalibr√°cie
6. Skreslenie je potrebn√© kompenzova≈• pre presn√© merania

3. OTAZKA: Predspracovanie obrazu, na ƒço sl√∫≈æi. ƒåo je to ≈°um, ako vznik√°, biely, gaussovsk√Ω, adit√≠vny, multplikat√≠vny, skladanie sign√°lov. Histogram jasu, ƒço to je, ako sa poƒç√≠ta pre digit√°lnu obrazov√∫ funkciu, ƒço vyjadruje pre spojit√∫, Bodov√© jasov√© transform√°cie: vyrovn√°vanie histogramu, ako sa vykon√°va a ak√Ω m√° vplyv na v√Ωsledn√Ω obraz. Ako sa vykon√°va jasov√° korekcia. ƒåo je to jasov√° stupnica, ako ju mo≈æno modifikova≈•. ƒåo je to kontrast v obraze, zv√Ω≈°enie a zn√≠≈æenie kontrastu, gamma korekcia

Priprav√≠m komplexn√∫ odpoveƒè o predspracovan√≠ obrazu a s√∫visiacich konceptoch.

1. Predspracovanie obrazu
- √öƒçel: zlep≈°enie kvality obrazu pre ƒèal≈°ie spracovanie
- Hlavn√© ciele:
  - Odstr√°nenie ≈°umu
  - Zlep≈°enie kontrastu
  - Korekcia jasov√Ωch nerovnomernost√≠
  - Zv√Ωraznenie charakterist√≠k pre ƒèal≈°iu anal√Ωzu

2. ≈†um v obraze

a) Typy ≈°umu:
- Biely ≈°um
  - N√°hodn√Ω sign√°l s rovnomern√Ωm v√Ωkonov√Ωm spektrom
  - Pr√≠klad v praxi:
  ```python
  white_noise = np.random.normal(0, 1, image.shape)
  noisy_image = image + white_noise
  ```

- Gaussovsk√Ω ≈°um
  - Hodnoty ≈°umu maj√∫ Gaussovo (norm√°lne) rozdelenie
  - Matematick√Ω model:
  ```
  p(z) = (1/‚àö(2œÄœÉ¬≤)) * e^(-(z-Œº)¬≤/2œÉ¬≤)
  kde:
  Œº - stredn√° hodnota
  œÉ¬≤ - rozptyl
  ```

b) Sp√¥sob pridania ≈°umu:
- Adit√≠vny ≈°um
  ```
  g(x,y) = f(x,y) + n(x,y)
  kde:
  f(x,y) - p√¥vodn√Ω obraz
  n(x,y) - ≈°um
  g(x,y) - v√Ωsledn√Ω obraz
  ```

- Multiplikat√≠vny ≈°um
  ```
  g(x,y) = f(x,y) * n(x,y)
  ```

3. Histogram jasu

a) Defin√≠cia:
- Pre diskr√©tny obraz:
  ```
  h(rk) = nk
  kde:
  rk - k-t√° √∫rove≈à jasu
  nk - poƒçet pixelov s jasom rk
  ```

- Pre spojit√Ω obraz:
  - Vyjadruje pravdepodobnos≈• v√Ωskytu danej jasovej √∫rovne
  - Integr√°l histogramu = 1

b) V√Ωpoƒçet histogramu v praxi:
```python
def calculate_histogram(image):
    histogram = np.zeros(256)
    for pixel_value in image.flatten():
        histogram[pixel_value] += 1
    return histogram
```

4. Bodov√© jasov√© transform√°cie

a) Vyrovn√°vanie histogramu:
- Cieƒæ: rovnomern√© rozlo≈æenie jasov√Ωch hodn√¥t
- Postup:
```python
def equalize_histogram(image):
    # V√Ωpoƒçet kumulat√≠vneho histogramu
    hist = np.bincount(image.ravel(), minlength=256)
    cum_hist = np.cumsum(hist)
    
    # Normaliz√°cia
    cum_hist = (cum_hist * 255) / cum_hist[-1]
    
    # Mapovanie hodn√¥t
    return cum_hist[image]
```

b) Jasov√° korekcia:
- Line√°rna transform√°cia:
  ```
  g(x,y) = a * f(x,y) + b
  kde:
  a - zmena kontrastu
  b - zmena jasu
  ```

5. Jasov√° stupnica a jej modifik√°cie

a) Z√°kladn√© transform√°cie:
- Line√°rna:
  ```
  g = a*f + b
  ```
- Logaritmick√°:
  ```
  g = c * log(1 + f)
  ```
- Exponenci√°lna:
  ```
  g = c * (e^f - 1)
  ```

6. Kontrast v obraze

a) Defin√≠cia:
- Rozdiel medzi najvy≈°≈°ou a najni≈æ≈°ou jasovou hodnotou
- Matematicky:
  ```
  C = (Imax - Imin)/(Imax + Imin)
  ```

b) √öprava kontrastu:
- Zv√Ω≈°enie:
  ```python
  def increase_contrast(image, factor):
      mean = np.mean(image)
      return (image - mean) * factor + mean
  ```

- Zn√≠≈æenie:
  ```python
  def decrease_contrast(image, factor):
      mean = np.mean(image)
      return (image - mean) / factor + mean
  ```

c) Gamma korekcia:
- Neline√°rna transform√°cia:
  ```
  g = c * f^Œ≥
  kde:
  Œ≥ < 1: zv√Ω≈°enie jasu v tmav√Ωch oblastiach
  Œ≥ > 1: zv√Ω≈°enie kontrastu v svetl√Ωch oblastiach
  ```

Praktick√Ω pr√≠klad implement√°cie gamma korekcie:
```python
def gamma_correction(image, gamma):
    # Normaliz√°cia do rozsahu 0-1
    normalized = image / 255.0
    
    # Aplik√°cia gamma korekcie
    corrected = np.power(normalized, gamma)
    
    # Sp√§≈• do rozsahu 0-255
    return (corrected * 255).astype(np.uint8)
```

D√¥le≈æit√© body na zapam√§tanie:
1. Predspracovanie je kƒæ√∫ƒçov√© pre √∫spe≈°n√∫ anal√Ωzu obrazu
2. R√¥zne typy ≈°umu vy≈æaduj√∫ r√¥zne met√≥dy odstr√°nenia
3. Histogram poskytuje d√¥le≈æit√© inform√°cie o rozlo≈æen√≠ jasu v obraze
4. Vyrovn√°vanie histogramu zlep≈°uje kontrast obrazu
5. Gamma korekcia je u≈æitoƒçn√° pre √∫pravu tmav√Ωch alebo svetl√Ωch ƒçast√≠ obrazu

4. OTAZKA : Geometrick√© transform√°cie obrazu, kedy ich mo≈æno pou≈æi≈• a ako? Rovnica afinnej transform√°cie, z√°pis pre posunutie, zmenu ≈°k√°ly. Rot√°cia. Na ƒço sa pri geometrick√Ωch transform√°ci√°ch pou≈æ√≠va interpol√°cia a ako. Z√°kladn√© typy interpol√°cie - najbli≈æ≈°√≠ sused, biline√°rna, bikubick√°. Demon≈°trujte na pr√≠klade. Ak√Ωm sp√¥sobom mo≈æno poƒç√≠ta≈• vzdialenos≈•, uveƒète v√Ωpoƒçet Euklidovskej vzdialenosti, city block a chessboard vzdialenosti, na ƒço sa pri interpol√°cii vzdialenos≈• poƒç√≠ta a medzi ƒç√≠m?

Priprav√≠m komplexn√© vysvetlenie geometrick√Ωch transform√°ci√≠ a s√∫visiacich konceptov.

1. Geometrick√© transform√°cie obrazu

Vyu≈æitie:
- Korekcia skreslenia
- Zmena veƒækosti obrazu
- Rot√°cia obrazu
- Registr√°cia obrazov
- Mapovanie text√∫r

2. Afinn√° transform√°cia

Z√°kladn√° rovnica:
```
[x']   [a11 a12 tx] [x]
[y'] = [a21 a22 ty] [y]
[1 ]   [0   0   1 ] [1]
```

a) Posunutie (transl√°cia):
```
[x']   [1 0 tx] [x]
[y'] = [0 1 ty] [y]
[1 ]   [0 0 1 ] [1]
```

b) Zmena mierky:
```
[x']   [sx 0  0] [x]
[y'] = [0  sy 0] [y]
[1 ]   [0  0  1] [1]
```

c) Rot√°cia o uhol Œ∏:
```
[x']   [cos(Œ∏) -sin(Œ∏) 0] [x]
[y'] = [sin(Œ∏)  cos(Œ∏) 0] [y]
[1 ]   [0       0      1] [1]
```

3. Interpol√°cia

Pou≈æ√≠va sa pri transform√°ci√°ch na v√Ωpoƒçet hodn√¥t pixelov v novej poz√≠cii.

a) Met√≥da najbli≈æ≈°ieho suseda:
```python
def nearest_neighbor(image, x, y):
    return image[round(y), round(x)]
```

b) Biline√°rna interpol√°cia:
```python
def bilinear_interpolation(image, x, y):
    x1, y1 = int(x), int(y)
    x2, y2 = x1 + 1, y1 + 1
    
    # V√°hy
    wx = x - x1
    wy = y - y1
    
    # Interpol√°cia
    value = (1-wx)*(1-wy)*image[y1,x1] + \
            wx*(1-wy)*image[y1,x2] + \
            (1-wx)*wy*image[y2,x1] + \
            wx*wy*image[y2,x2]
    
    return value
```

c) Bikubick√° interpol√°cia:
- Pou≈æ√≠va 16 okolot√Ωch bodov (4x4)
- Poskytuje hlad≈°ie v√Ωsledky ale je v√Ωpoƒçtovo n√°roƒçnej≈°ia

4. V√Ωpoƒçet vzdialenost√≠

a) Euklidovsk√° vzdialenos≈•:
```python
def euclidean_distance(x1, y1, x2, y2):
    return np.sqrt((x2-x1)**2 + (y2-y1)**2)
```

b) City block (Manhattan) vzdialenos≈•:
```python
def city_block_distance(x1, y1, x2, y2):
    return abs(x2-x1) + abs(y2-y1)
```

c) Chessboard vzdialenos≈•:
```python
def chessboard_distance(x1, y1, x2, y2):
    return max(abs(x2-x1), abs(y2-y1))
```

Praktick√Ω pr√≠klad rot√°cie obrazu:
```python
def rotate_image(image, angle_degrees):
    # Konverzia uhla na radi√°ny
    angle_radians = np.radians(angle_degrees)
    
    # V√Ωpoƒçet stredu obrazu
    height, width = image.shape[:2]
    center_x, center_y = width/2, height/2
    
    # Rotaƒçn√° matica
    rotation_matrix = np.array([
        [np.cos(angle_radians), -np.sin(angle_radians)],
        [np.sin(angle_radians),  np.cos(angle_radians)]
    ])
    
    # Nov√Ω obraz
    result = np.zeros_like(image)
    
    # Aplik√°cia rot√°cie s biline√°rnou interpol√°ciou
    for y in range(height):
        for x in range(width):
            # Posun do stredu
            pos = np.array([x - center_x, y - center_y])
            # Rot√°cia
            new_pos = rotation_matrix @ pos
            # Posun sp√§≈•
            new_x = new_pos[0] + center_x
            new_y = new_pos[1] + center_y
            
            # Kontrola hran√≠c
            if 0 <= new_x < width-1 and 0 <= new_y < height-1:
                result[y,x] = bilinear_interpolation(image, new_x, new_y)
    
    return result
```

Pr√≠klad pou≈æitia r√¥znych typov vzdialenost√≠ pri interpol√°cii:
```python
def weighted_interpolation(image, x, y, distance_type='euclidean'):
    # N√°jdenie 4 najbli≈æ≈°√≠ch bodov
    x1, y1 = int(x), int(y)
    x2, y2 = x1 + 1, y1 + 1
    
    points = [(x1,y1), (x1,y2), (x2,y1), (x2,y2)]
    weights = []
    
    # V√Ωpoƒçet v√°h podƒæa zvolenej metriky
    for px, py in points:
        if distance_type == 'euclidean':
            d = euclidean_distance(x, y, px, py)
        elif distance_type == 'city_block':
            d = city_block_distance(x, y, px, py)
        else:  # chessboard
            d = chessboard_distance(x, y, px, py)
        
        # Prevod vzdialenosti na v√°hu
        weights.append(1 / (d + 0.0001))  # Prevencia delenia nulou
    
    # Normaliz√°cia v√°h
    weights = np.array(weights)
    weights = weights / np.sum(weights)
    
    # V√Ωpoƒçet interpolovanej hodnoty
    value = 0
    for (px,py), w in zip(points, weights):
        value += image[py,px] * w
        
    return value
```

Kƒæ√∫ƒçov√© body na zapam√§tanie:
1. Afinn√© transform√°cie zachov√°vaj√∫ rovnobe≈ænos≈• l√≠ni√≠
2. V√Ωber interpolaƒçnej met√≥dy ovplyv≈àuje kvalitu v√Ωsledn√©ho obrazu
3. R√¥zne metriky vzdialenosti m√¥≈æu by≈• vhodn√© pre r√¥zne aplik√°cie
4. Biline√°rna interpol√°cia poskytuje dobr√Ω kompromis medzi kvalitou a v√Ωpoƒçtovou n√°roƒçnos≈•ou
5. Pri transform√°ci√°ch je d√¥le≈æit√© spr√°vne o≈°etri≈• hranice obrazu

5. OTAZKA: Gradient v ≈°edot√≥novom obraze, ƒço to je a ƒçomu zodpoved√°? Ako aproximujeme v√Ωpoƒçet gradientu v digit√°lnom obraze? ƒåo je to hrana, ako je definovan√°, uveƒète niektor√© typy hr√°n. ƒåo je to detekcia hr√°n a ako funguje Cannyho detektor hr√°n

Priprav√≠m podrobn√© vysvetlenie gradientu obrazu a detekcie hr√°n.

1. Gradient v ≈°edot√≥novom obraze

- Defin√≠cia: Gradient predstavuje smer a veƒækos≈• najv√§ƒç≈°ej zmeny jasu v obraze
- Matematick√Ω z√°pis:
```
‚àáf = [‚àÇf/‚àÇx, ‚àÇf/‚àÇy]
kde:
‚àÇf/‚àÇx - parci√°lna deriv√°cia v smere x
‚àÇf/‚àÇy - parci√°lna deriv√°cia v smere y
```

- Veƒækos≈• (magnit√∫da) gradientu:
```
|‚àáf| = ‚àö[(‚àÇf/‚àÇx)¬≤ + (‚àÇf/‚àÇy)¬≤]
```

- Smer gradientu:
```
Œ∏ = arctan(‚àÇf/‚àÇy / ‚àÇf/‚àÇx)
```

2. Aproxim√°cia gradientu v digit√°lnom obraze

a) Z√°kladn√© oper√°tory:
- Robertsov oper√°tor:
```
Gx = [+1  0] Gy = [ 0 +1]
     [ 0 -1]      [-1  0]
```

- Sobelov oper√°tor:
```
Gx = [-1 0 +1] Gy = [+1 +2 +1]
     [-2 0 +2]      [ 0  0  0]
     [-1 0 +1]      [-1 -2 -1]
```

- Prewittovej oper√°tor:
```
Gx = [-1 0 +1] Gy = [+1 +1 +1]
     [-1 0 +1]      [ 0  0  0]
     [-1 0 +1]      [-1 -1 -1]
```

3. Hrany v obraze

a) Defin√≠cia:
- Hrana je miesto v obraze, kde doch√°dza k v√Ωraznej zmene jasovej funkcie

b) Typy hr√°n:
1. Skokov√° hrana (step edge):
```
Jasov√° funkcia:  _____
                     |_____
```

2. L√≠niov√° hrana (line edge):
```
Jasov√° funkcia:  _____
                     |‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ
```

3. Stre≈°n√° hrana (roof edge):
```
Jasov√° funkcia:      /\
                 ___/  \___
```

4. Rampov√° hrana (ramp edge):
```
Jasov√° funkcia:  ____
                    /____
```

4. Cannyho detektor hr√°n

Postup:
1. Redukcia ≈°umu (Gaussov filter)
```python
def gaussian_filter(image, sigma):
    size = int(6 * sigma + 1)
    kernel = np.zeros((size, size))
    center = size // 2
    
    for i in range(size):
        for j in range(size):
            x = i - center
            y = j - center
            kernel[i,j] = np.exp(-(x**2 + y**2)/(2*sigma**2))
    
    kernel = kernel / np.sum(kernel)
    return cv2.filter2D(image, -1, kernel)
```

2. V√Ωpoƒçet gradientu (Sobelove oper√°tory):
```python
def compute_gradient(image):
    gx = cv2.Sobel(image, cv2.CV_64F, 1, 0)
    gy = cv2.Sobel(image, cv2.CV_64F, 0, 1)
    
    magnitude = np.sqrt(gx**2 + gy**2)
    direction = np.arctan2(gy, gx)
    
    return magnitude, direction
```

3. Potlaƒçenie nemaxim√°lnych hodn√¥t (Non-maximum suppression):
```python
def non_max_suppression(magnitude, direction):
    height, width = magnitude.shape
    result = np.zeros_like(magnitude)
    
    # Kvantiz√°cia smeru do 4 smerov (0¬∞, 45¬∞, 90¬∞, 135¬∞)
    direction = np.rad2deg(direction) % 180
    
    for i in range(1, height-1):
        for j in range(1, width-1):
            # Porovnanie s dvoma susedn√Ωmi pixelmi v smere gradientu
            if (0 <= direction[i,j] < 22.5) or (157.5 <= direction[i,j] <= 180):
                neighbors = [magnitude[i,j+1], magnitude[i,j-1]]
            elif (22.5 <= direction[i,j] < 67.5):
                neighbors = [magnitude[i-1,j+1], magnitude[i+1,j-1]]
            elif (67.5 <= direction[i,j] < 112.5):
                neighbors = [magnitude[i-1,j], magnitude[i+1,j]]
            else:
                neighbors = [magnitude[i-1,j-1], magnitude[i+1,j+1]]
            
            if magnitude[i,j] >= max(neighbors):
                result[i,j] = magnitude[i,j]
    
    return result
```

4. Dvojit√© prahovanie (Double thresholding):
```python
def double_thresholding(image, low_ratio=0.05, high_ratio=0.15):
    high_threshold = image.max() * high_ratio
    low_threshold = high_threshold * low_ratio
    
    strong_edges = (image >= high_threshold)
    weak_edges = (image >= low_threshold) & (image < high_threshold)
    
    return strong_edges, weak_edges
```

5. Sledovanie hr√°n hyster√©ziou (Edge tracking by hysteresis):
```python
def edge_tracking(strong_edges, weak_edges):
    height, width = strong_edges.shape
    result = np.copy(strong_edges)
    
    # Sledovanie slab√Ωch hr√°n pripojen√Ωch k siln√Ωm
    for i in range(1, height-1):
        for j in range(1, width-1):
            if weak_edges[i,j]:
                # Kontrola 8-okolia
                if np.any(strong_edges[i-1:i+2, j-1:j+2]):
                    result[i,j] = True
    
    return result
```

Kompletn√Ω Cannyho detektor:
```python
def canny_detector(image, sigma=1, low_ratio=0.05, high_ratio=0.15):
    # 1. Redukcia ≈°umu
    smoothed = gaussian_filter(image, sigma)
    
    # 2. V√Ωpoƒçet gradientu
    magnitude, direction = compute_gradient(smoothed)
    
    # 3. Potlaƒçenie nemaxim√°lnych hodn√¥t
    suppressed = non_max_suppression(magnitude, direction)
    
    # 4. Dvojit√© prahovanie
    strong_edges, weak_edges = double_thresholding(suppressed, 
                                                 low_ratio, 
                                                 high_ratio)
    
    # 5. Sledovanie hr√°n
    edges = edge_tracking(strong_edges, weak_edges)
    
    return edges
```

Kƒæ√∫ƒçov√© body na zapam√§tanie:
1. Gradient poskytuje inform√°cie o smere a veƒækosti zmeny jasu
2. Existuj√∫ r√¥zne typy hr√°n v z√°vislosti od priebehu jasovej funkcie
3. Cannyho detektor je robustn√Ω algoritmus zah≈ï≈àaj√∫ci viacero krokov
4. V√Ωber prahov v Cannyho detektore v√Ωznamne ovplyv≈àuje v√Ωsledok
5. Potlaƒçenie nemaxim√°lnych hodn√¥t je kƒæ√∫ƒçov√© pre z√≠skanie tenk√Ωch hr√°n

6. OTAZKA: Ako je definovan√° oper√°cia konvol√∫cie pre digit√°lne obrazy? Pop√≠≈°te aplik√°ciu vybranej konvoluƒçnej masky na obraz. Ak√© s√∫ masky pre vyhladzovanie a pre ostrenie obrazu (zv√Ωraznenie hr√°n, v≈°esmerov√© a smerov√©)? Ako mo≈æno konvol√∫ciu vyu≈æi≈• na vyhƒæad√°vanie vzoru? Kedy a preƒço to funguje, ak√© s√∫ obmedzenia?

Priprav√≠m komplexn√© vysvetlenie konvol√∫cie a jej vyu≈æitia v spracovan√≠ obrazu.

1. Defin√≠cia konvol√∫cie pre digit√°lne obrazy

Matematick√Ω z√°pis:
```
g(x,y) = f(x,y) * h(x,y) = Œ£ Œ£ f(i,j) * h(x-i, y-j)
```
kde:
- f(x,y) je vstupn√Ω obraz
- h(x,y) je konvoluƒçn√° maska (kernel)
- g(x,y) je v√Ωstupn√Ω obraz

Implement√°cia konvol√∫cie:
```python
def convolution2d(image, kernel):
    # Rozmery obrazu a kernelu
    i_height, i_width = image.shape
    k_height, k_width = kernel.shape
    
    # Padding
    pad_h = k_height // 2
    pad_w = k_width // 2
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), 'edge')
    
    # V√Ωstupn√Ω obraz
    output = np.zeros_like(image)
    
    # Konvol√∫cia
    for y in range(i_height):
        for x in range(i_width):
            # V√Ωrez obrazu pod kernelom
            region = padded[y:y+k_height, x:x+k_width]
            # Aplik√°cia kernelu
            output[y,x] = np.sum(region * kernel)
            
    return output
```

2. Konvoluƒçn√© masky

a) Vyhladzovanie obrazu:
- Priemerovacia maska (box filter):
```
[1/9 1/9 1/9]
[1/9 1/9 1/9]
[1/9 1/9 1/9]
```

- Gaussova maska (œÉ=1):
```
[1/16 2/16 1/16]
[2/16 4/16 2/16]
[1/16 2/16 1/16]
```

b) Ostrenie obrazu (zv√Ωraznenie hr√°n):
- Laplaci√°n (v≈°esmerov√Ω):
```
[0  1  0]
[1 -4  1]
[0  1  0]
```

- Sobelove masky (smerov√©):
Horizont√°lna:
```
[-1 -2 -1]
[ 0  0  0]
[ 1  2  1]
```
Vertik√°lna:
```
[-1  0  1]
[-2  0  2]
[-1  0  1]
```

3. Vyhƒæad√°vanie vzoru pomocou konvol√∫cie

Princ√≠p:
```python
def template_matching(image, template):
    # Normaliz√°cia template
    template = template - np.mean(template)
    template = template / np.std(template)
    
    # Konvol√∫cia
    result = convolution2d(image, template)
    
    # Normaliz√°cia v√Ωsledku
    result = (result - np.mean(result)) / np.std(result)
    
    return result
```

Pr√≠klad pou≈æitia:
```python
def find_pattern(image, pattern, threshold=0.8):
    # Aplik√°cia template matching
    correlation = template_matching(image, pattern)
    
    # N√°jdenie max√≠m
    locations = np.where(correlation > threshold)
    
    return list(zip(locations[1], locations[0]))  # x, y koordin√°ty
```

Obmedzenia template matchingu:
1. Citlivos≈• na rot√°ciu
```python
# Rie≈°enie - vytvorenie rotovan√Ωch verzi√≠ vzoru
def create_rotated_templates(template, angles):
    templates = []
    for angle in angles:
        rotated = rotate_image(template, angle)
        templates.append(rotated)
    return templates
```

2. Citlivos≈• na zmenu mierky
```python
# Rie≈°enie - vytvorenie vzoru v r√¥znych mierkach
def create_scaled_templates(template, scales):
    templates = []
    for scale in scales:
        scaled = cv2.resize(template, None, fx=scale, fy=scale)
        templates.append(scaled)
    return templates
```

3. Citlivos≈• na zmenu osvetlenia
```python
# Rie≈°enie - normaliz√°cia jasu
def normalize_brightness(image):
    return (image - np.mean(image)) / np.std(image)
```

4. Praktick√© pou≈æitie konvol√∫cie

a) Implement√°cia r√¥znych filtrov:
```python
def apply_filter(image, filter_type):
    if filter_type == 'blur':
        kernel = np.ones((3,3)) / 9
    elif filter_type == 'sharpen':
        kernel = np.array([
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
        ])
    elif filter_type == 'edge_detect':
        kernel = np.array([
            [-1, -1, -1],
            [-1, 8, -1],
            [-1, -1, -1]
        ])
        
    return convolution2d(image, kernel)
```

b) Kombin√°cia filtrov:
```python
def enhance_image(image):
    # Najprv redukcia ≈°umu
    blurred = apply_filter(image, 'blur')
    
    # Potom zv√Ωraznenie hr√°n
    enhanced = apply_filter(blurred, 'sharpen')
    
    return enhanced
```

Kƒæ√∫ƒçov√© body na zapam√§tanie:
1. Konvol√∫cia je z√°kladn√° oper√°cia v spracovan√≠ obrazu
2. R√¥zne masky poskytuj√∫ r√¥zne efekty (vyhladzovanie, ostrenie)
3. Template matching je citliv√Ω na rot√°ciu, mierku a osvetlenie
4. Pre robustn√© vyhƒæad√°vanie vzoru je potrebn√© pou≈æi≈• viacero variant vzoru
5. Spr√°vny v√Ωber konvoluƒçnej masky z√°vis√≠ od konkr√©tnej aplik√°cie

7. OTAZKA: Definujte Fourierovu transform√°ciu, ƒço je jej vstupom a ƒço v√Ωstupom? Ak√© s√∫ met√≥dy zobrazenia frekvenƒçn√©ho spektra? ƒåomu zodpovedaj√∫ frekvencie ak hovor√≠me o 2D obraze? Ak√Ωm sp√¥sobom m√¥≈æeme pou≈æi≈• filtrovanie vo frekvenƒçnom spektre a ak√Ω je cel√Ω postup pre z√≠skanie filtrovan√©ho obrazu? Ak√Ω je vz≈•ah konvol√∫cie a Fourierovej transform√°cie? Na ak√© √∫ƒçely mo≈æno e≈°te pou≈æi≈• anal√Ωzu frekvenƒçn√©ho spektra

Priprav√≠m komplexn√© vysvetlenie Fourierovej transform√°cie a jej vyu≈æitia v spracovan√≠ obrazu.

1. Fourierova transform√°cia (FT)

Defin√≠cia pre 2D obraz:
```
F(u,v) = ‚à´‚à´ f(x,y) * e^(-j2œÄ(ux+vy)) dx dy
```
kde:
- f(x,y) je vstupn√Ω obraz v priestorovej dom√©ne
- F(u,v) je obraz vo frekvenƒçnej dom√©ne
- u,v s√∫ frekvenƒçn√© premenn√©

Diskr√©tna Fourierova transform√°cia (DFT):
```python
def compute_dft(image):
    # Pou≈æitie FFT algoritmu
    f_transform = np.fft.fft2(image)
    # Presun nulov√Ωch frekvenci√≠ do stredu
    f_transform_shifted = np.fft.fftshift(f_transform)
    return f_transform_shifted
```

2. Zobrazenie frekvenƒçn√©ho spektra

a) Amplit√∫dov√© spektrum:
```python
def display_spectrum(f_transform):
    magnitude_spectrum = np.abs(f_transform)
    # Logaritmick√° transform√°cia pre lep≈°iu vizualiz√°ciu
    log_spectrum = np.log1p(magnitude_spectrum)
    return log_spectrum

def normalize_spectrum(spectrum):
    return (spectrum - np.min(spectrum)) / (np.max(spectrum) - np.min(spectrum))
```

b) F√°zov√© spektrum:
```python
def display_phase(f_transform):
    phase_spectrum = np.angle(f_transform)
    return phase_spectrum
```

3. V√Ωznam frekvenci√≠ v 2D obraze:

- N√≠zke frekvencie (stred spektra):
  - Zodpovedaj√∫ pomaly sa meniacim jasom
  - Reprezentuj√∫ hrub√© ≈°trukt√∫ry a pozadie

- Vysok√© frekvencie (okraje spektra):
  - Zodpovedaj√∫ r√Ωchlym zmen√°m jasu
  - Reprezentuj√∫ hrany a detaily

4. Filtrovanie vo frekvenƒçnej dom√©ne

a) Dolnopriepustn√Ω filter (potlaƒçenie vysok√Ωch frekvenci√≠):
```python
def lowpass_filter(shape, cutoff):
    rows, cols = shape
    crow, ccol = rows//2, cols//2
    
    # Vytvorenie masky
    mask = np.zeros((rows, cols))
    y, x = np.ogrid[-crow:rows-crow, -ccol:cols-ccol]
    mask_area = x*x + y*y <= cutoff*cutoff
    mask[mask_area] = 1
    
    return mask
```

b) Hornopriepustn√Ω filter (potlaƒçenie n√≠zkych frekvenci√≠):
```python
def highpass_filter(shape, cutoff):
    return 1 - lowpass_filter(shape, cutoff)
```

Cel√Ω proces filtrovania:
```python
def frequency_domain_filter(image, filter_mask):
    # 1. V√Ωpoƒçet DFT
    f_transform = compute_dft(image)
    
    # 2. Aplik√°cia filtra
    filtered_f = f_transform * filter_mask
    
    # 3. Inverzn√° DFT
    filtered_image = np.abs(np.fft.ifft2(np.fft.ifftshift(filtered_f)))
    
    return filtered_image
```

5. Vz≈•ah konvol√∫cie a Fourierovej transform√°cie

Konvoluƒçn√Ω teor√©m:
```
f(x,y) * h(x,y) ‚Üê‚Üí F(u,v) ¬∑ H(u,v)
```
kde:
- * oznaƒçuje konvol√∫ciu
- ¬∑ oznaƒçuje n√°sobenie po prvkoch
- F(u,v) je FT obrazu
- H(u,v) je FT konvoluƒçnej masky

Implement√°cia:
```python
def convolution_frequency(image, kernel):
    # FT obrazu
    F = np.fft.fft2(image)
    # FT kernelu (potrebn√© doplni≈• na veƒækos≈• obrazu)
    H = np.fft.fft2(kernel, s=image.shape)
    # N√°sobenie vo frekvenƒçnej dom√©ne
    G = F * H
    # Inverzn√° FT
    result = np.real(np.fft.ifft2(G))
    return result
```

6. ƒéal≈°ie vyu≈æitie frekvenƒçn√©ho spektra

a) Anal√Ωza text√∫r:
```python
def analyze_texture(image):
    f_transform = compute_dft(image)
    spectrum = np.abs(f_transform)
    
    # Rozdelenie spektra na prstence
    rings = []
    center_y, center_x = spectrum.shape[0]//2, spectrum.shape[1]//2
    
    for r in range(0, min(center_x, center_y), 10):
        y, x = np.ogrid[-center_y:spectrum.shape[0]-center_y,
                       -center_x:spectrum.shape[1]-center_x]
        mask = (x*x + y*y >= r**2) & (x*x + y*y < (r+10)**2)
        rings.append(np.mean(spectrum[mask]))
        
    return rings  # Charakteristika text√∫ry
```

b) Detekcia periodick√Ωch vzorov:
```python
def detect_patterns(image):
    f_transform = compute_dft(image)
    spectrum = np.abs(f_transform)
    
    # Hƒæadanie lok√°lnych max√≠m v spektre
    from scipy.signal import find_peaks_cwt
    peaks = find_peaks_cwt(spectrum.ravel(), np.arange(1,10))
    
    return peaks
```

Kƒæ√∫ƒçov√© body na zapam√§tanie:
1. FT rozklad√° obraz na frekvenƒçn√© komponenty
2. N√≠zke frekvencie zodpovedaj√∫ hrub√Ωm ≈°trukt√∫ram, vysok√© detailom
3. Filtrovanie vo frekvenƒçnej dom√©ne je ekvivalentn√© konvol√∫cii
4. Frekvenƒçn√© spektrum poskytuje u≈æitoƒçn√© inform√°cie o ≈°trukt√∫re obrazu
5. FT je reverzibiln√° - m√¥≈æeme sa vr√°ti≈• do priestorovej dom√©ny

8. OTAZKA: ƒåo je to segment√°cia obrazu? Segment√°cia obrazu podƒæa jasu, prahovanie jedn√Ωm, dvomi, viacer√Ωmi prahmi. Met√≥dy automatick√©ho urƒçovania prahu - iterat√≠vny algoritmus hƒæadania optim√°lneho prahu. ƒåo je to adapt√≠vne prahovanie, uveƒète pr√≠klad aplik√°cie adapt√≠vneho prahovania na segment√°ciu textu z nerovnomerne osvetlen√©ho povrchu

Priprav√≠m komplexn√© vysvetlenie segment√°cie obrazu a r√¥znych met√≥d prahovania.

1. Segment√°cia obrazu
- Cieƒæ: rozdelenie obrazu na oblasti so spoloƒçn√Ωmi vlastnos≈•ami
- V√Ωstup: obraz, kde ka≈æd√Ω pixel patr√≠ do urƒçitej triedy/segmentu
- Vyu≈æitie: rozpozn√°vanie objektov, anal√Ωza sc√©ny, spracovanie dokumentov

2. Segment√°cia podƒæa jasu (Prahovanie)

a) Prahovanie jedn√Ωm prahom:
```python
def simple_threshold(image, threshold):
    return np.where(image > threshold, 255, 0)
```

b) Prahovanie dvoma prahmi:
```python
def dual_threshold(image, low_threshold, high_threshold):
    result = np.zeros_like(image)
    result[(image >= low_threshold) & (image <= high_threshold)] = 255
    return result
```

c) Prahovanie viacer√Ωmi prahmi:
```python
def multi_threshold(image, thresholds):
    result = np.zeros_like(image)
    for i, threshold in enumerate(thresholds[:-1]):
        mask = (image >= threshold) & (image < thresholds[i+1])
        result[mask] = i * (255 // (len(thresholds)-1))
    return result
```

3. Automatick√© urƒçovanie prahu

Iterat√≠vny algoritmus (Otsu):
```python
def otsu_threshold(image):
    # V√Ωpoƒçet histogramu
    hist = np.histogram(image, bins=256, range=[0,256])[0]
    hist = hist / hist.sum()
    
    # Inicializ√°cia
    best_threshold = 0
    best_variance = 0
    
    # Prechod v≈°etk√Ωmi mo≈æn√Ωmi prahmi
    for threshold in range(1, 255):
        # Rozdelenie histogramu
        w0 = hist[:threshold].sum()
        w1 = hist[threshold:].sum()
        
        if w0 == 0 or w1 == 0:
            continue
            
        # V√Ωpoƒçet priemerov
        mu0 = np.average(range(threshold), weights=hist[:threshold])
        mu1 = np.average(range(threshold, 256), weights=hist[threshold:])
        
        # V√Ωpoƒçet medzi-triednej variancie
        variance = w0 * w1 * (mu0 - mu1) ** 2
        
        # Aktualiz√°cia najlep≈°ieho prahu
        if variance > best_variance:
            best_variance = variance
            best_threshold = threshold
            
    return best_threshold
```

4. Adapt√≠vne prahovanie

Implement√°cia adapt√≠vneho prahovania:
```python
def adaptive_threshold(image, window_size=11, C=2):
    # Vytvorenie pr√°zdneho v√Ωstupn√©ho obrazu
    result = np.zeros_like(image)
    
    # Padding obrazu
    pad = window_size // 2
    padded = np.pad(image, pad, mode='edge')
    
    # Prechod obrazom
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            # V√Ωrez okna
            window = padded[i:i+window_size, j:j+window_size]
            # V√Ωpoƒçet lok√°lneho prahu
            local_threshold = np.mean(window) - C
            # Prahovanie
            result[i,j] = 255 if image[i,j] > local_threshold else 0
            
    return result
```

Vylep≈°en√° verzia pre nerovnomerne osvetlen√Ω text:
```python
def adaptive_document_threshold(image, window_size=51, C=10):
    # Gaussovo rozmazanie pre odhad pozadia
    blur = cv2.GaussianBlur(image, (window_size, window_size), 0)
    
    # Adapt√≠vne prahovanie pomocou lok√°lneho kontrastu
    threshold = blur - C
    result = np.where(image > threshold, 255, 0)
    
    return result.astype(np.uint8)
```

Pr√≠klad pou≈æitia pre dokument:
```python
def process_document(image_path):
    # Naƒç√≠tanie obrazu
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    # Aplik√°cia adapt√≠vneho prahovania
    binary = adaptive_document_threshold(image)
    
    # Odstr√°nenie ≈°umu
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    
    return cleaned
```

5. Praktick√© pr√≠klady vyu≈æitia:

a) Segment√°cia textu z dokumentu s tie≈àom:
```python
def segment_shadowed_document(image):
    # Normaliz√°cia kontrastu
    normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)
    
    # Adapt√≠vne prahovanie s veƒæk√Ωm oknom
    binary = cv2.adaptiveThreshold(
        normalized,
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=51,
        C=25
    )
    
    return binary
```

b) Segment√°cia s premenliv√Ωm osvetlen√≠m:
```python
def segment_variable_lighting(image):
    # Odhad pozadia
    background = cv2.medianBlur(image, 51)
    
    # Korekcia osvetlenia
    corrected = cv2.subtract(image, background)
    normalized = cv2.normalize(corrected, None, 0, 255, cv2.NORM_MINMAX)
    
    # Prahovanie
    return adaptive_threshold(normalized)
```

Kƒæ√∫ƒçov√© body na zapam√§tanie:
1. Glob√°lne prahovanie funguje dobre len pri rovnomernom osvetlen√≠
2. Otsu met√≥da je efekt√≠vna pre bimod√°lne histogramy
3. Adapt√≠vne prahovanie je vhodn√© pre nerovnomerne osvetlen√© obrazy
4. Veƒækos≈• okna pri adapt√≠vnom prahovan√≠ ovplyv≈àuje v√Ωsledok
5. Pre dokumenty je ƒçasto potrebn√© kombinova≈• viacero techn√≠k

9. OTAZKA: Farba a farebn√© modely (adit√≠vne a subtrakt√≠vne), porovnajte RGB a Lab model z hƒæadiska segment√°cie objektov podƒæa farby, vysvetlite segment√°ciu podƒæa farby s pou≈æit√≠m Lab farebn√©ho modelu, mo≈ænosti vymedzenia oblast√≠ zodpovedaj√∫cich konkr√©tnej farbe. Segment√°cia ≈°tiepen√≠m a sp√°jan√≠m oblast√≠. Ako postupujeme pri jednotliv√Ωch met√≥dach, ako je ich mo≈æn√© kombinova≈•. ƒåo je to ‚Äúkrit√©rium homogenity‚Äù, uveƒète pr√≠klad. Ako funguje pyramid linking?

### **Farba a farebn√© modely (adit√≠vne a subtrakt√≠vne)**

**Adit√≠vne farebn√© modely (RGB):**
- Pou≈æ√≠vaj√∫ sa tam, kde je zdrojom farby svetlo, napr. v monitoroch, telev√≠zi√°ch, projektoroch.
- Z√°kladn√© farby: **ƒçerven√° (Red), zelen√° (Green), modr√° (Blue)**.
- Pri ich kombin√°cii vznikaj√∫ ostatn√© farby: 
  - ƒåerven√° + zelen√° = ≈ælt√°
  - ƒåerven√° + modr√° = purpurov√°
  - Zelen√° + modr√° = tyrkysov√°
  - V≈°etky tri dohromady = biela.
- Model je vhodn√Ω na zobrazenie farieb na zariadeniach, ktor√© vy≈æaduj√∫ emisiu svetla.

**Subtrakt√≠vne farebn√© modely (CMY/CMYK):**
- Pou≈æ√≠vaj√∫ sa pri tlaƒçi a v pr√≠pade pigmentov, kde farba vznik√° absorbovan√≠m (subtrakciou) svetla.
- Z√°kladn√© farby: **az√∫rov√° (Cyan), purpurov√° (Magenta), ≈ælt√° (Yellow)**. 
- Pri tlaƒçi sa prid√°va ƒçierna (Key/Black ‚Äì CMYK), aby bola ƒçierna farba presnej≈°ia.
- Kombin√°cia v≈°etk√Ωch troch pigmentov teoreticky vytv√°ra ƒçiernu, no v praxi je to tmavohned√°.

---

### **Porovnanie RGB a Lab modelu z hƒæadiska segment√°cie objektov podƒæa farby**

1. **RGB farebn√Ω model:**
   - Je vhodn√Ω na zobrazovanie farieb, ale menej vhodn√Ω na segment√°ciu, preto≈æe je z√°visl√Ω od osvetlenia.
   - Farby v RGB nie s√∫ line√°rne pr√≠buzn√© vn√≠maniu farieb ƒçlovekom ‚Äì mal√© zmeny hodn√¥t m√¥≈æu ma≈• nepredv√≠dateƒæn√Ω vizu√°lny efekt.
   - Napr√≠klad tie≈à alebo zmena intenzity osvetlenia ovplyv≈àuje hodnoty R, G a B, ƒço komplikuje segment√°ciu.

2. **Lab farebn√Ω model:**
   - Lab model je percepƒçne zalo≈æen√Ω a nez√°vis√≠ od osvetlenia (pokiaƒæ je normalizovan√Ω).
   - Obsahuje:
     - **L** (Lightness) ‚Äì jasov√° zlo≈æka.
     - **a** (Green to Magenta) ‚Äì farebn√Ω kan√°l.
     - **b** (Blue to Yellow) ‚Äì farebn√Ω kan√°l.
   - Lep≈°ie oddeƒæuje farebn√© inform√°cie od intenzity osvetlenia, ƒço uƒæahƒçuje segment√°ciu objektov na z√°klade farby, najm√§ v nehomog√©nne osvetlen√Ωch sc√©nach.

---

### **Segment√°cia podƒæa farby s pou≈æit√≠m Lab farebn√©ho modelu**

1. **Postup:**
   - Prevedieme obr√°zok z RGB modelu do Lab modelu.
   - Pou≈æijeme len farebn√© kan√°ly **a** a **b**, ƒç√≠m odstr√°nime vplyv osvetlenia.
   - Definujeme hranice pre farebn√© hodnoty **a** a **b**, ktor√© odpovedaj√∫ farbe z√°ujmu (napr. ƒçerven√° farba m√° hodnoty a > 20, b < 20).
   - Na z√°klade t√Ωchto hran√≠c identifikujeme pixely zodpovedaj√∫ce farbe z√°ujmu.

2. **Pr√≠klad:**
   - Ak chceme n√°js≈• ƒçerven√© oblasti:
     - Pre ka≈æd√Ω pixel vypoƒç√≠tame hodnoty **a** a **b**.
     - Ak hodnoty spadaj√∫ do rozsahu charakteristick√©ho pre ƒçerven√∫ farbu, pixel oznaƒç√≠me ako patriaci k ƒçervenej oblasti.

3. **Vymedzenie oblast√≠ podƒæa farby:**
   - Pou≈æ√≠vaj√∫ sa prahovacie techniky (thresholding).
   - Napr. pixely s hodnotami **a > X1** a **b < X2** oznaƒç√≠me ako ‚Äûƒçerven√©‚Äú.
   - V√Ωstupom je bin√°rna maska, kde 1 reprezentuje oblas≈• z√°ujmu.

---

### **Segment√°cia ≈°tiepen√≠m a sp√°jan√≠m oblast√≠**

1. **≈†tiepenie (Splitting):**
   - Rozdeƒæujeme obr√°zok na men≈°ie homog√©nne ƒçasti.
   - Pou≈æ√≠va sa, ak veƒæk√© oblasti nie s√∫ homog√©nne.
   - Postup:
     - Zaƒçneme s celou oblas≈•ou.
     - Skontrolujeme, ƒçi spƒ∫≈àa krit√©rium homogenity.
     - Ak nie, oblas≈• rozdel√≠me (napr. na ≈°tvrtiny).
     - Opakujeme, k√Ωm v≈°etky oblasti nie s√∫ homog√©nne.

2. **Sp√°janie (Merging):**
   - Spojujeme mal√© oblasti do v√§ƒç≈°√≠ch, ak spƒ∫≈àaj√∫ krit√©rium homogenity.
   - Pou≈æ√≠va sa po ≈°tiepen√≠ na optimaliz√°ciu segment√°cie.
   - Postup:
     - Skontrolujeme susedn√© oblasti.
     - Ak maj√∫ podobn√© hodnoty (napr. farebn√© alebo text√∫rne), spoj√≠me ich do jednej oblasti.

3. **Kombin√°cia met√≥d:**
   - **≈†tiepenie** pou≈æijeme na vytvorenie z√°kladn√Ωch homog√©nnych oblast√≠.
   - **Sp√°janie** n√°sledne spoj√≠ susedn√© homog√©nne oblasti, ƒç√≠m minimalizuje prebytoƒçn√© segmenty.

---

### **Krit√©rium homogenity**

- **Defin√≠cia:** Podmienka, ktor√° urƒçuje, ƒçi je oblas≈• dostatoƒçne jednotn√° na to, aby bola pova≈æovan√° za homog√©nnu.
- M√¥≈æe by≈• zalo≈æen√© na:
  - Hodnot√°ch farby (napr. vari√°cia vo farebn√Ωch kan√°loch < prah).
  - Text√∫re (napr. rovnak√° frekvencia pixelov v oblasti).
  - Jasnosti (napr. priemern√° intenzita v oblasti ¬± odch√Ωlka).
- **Pr√≠klad:** Oblas≈• je homog√©nna, ak vari√°cia hodnoty ‚Äûa‚Äú a ‚Äûb‚Äú v Lab modeli je men≈°ia ako 5.

---

### **Pyramid Linking**

- **Defin√≠cia:** Met√≥da, ktor√° sp√°ja inform√°cie z viacer√Ωch √∫rovn√≠ rozl√≠≈°enia obr√°zka.
- Postup:
  - Vytvor√≠ sa pyram√≠da obr√°zkov:
    - Najvy≈°≈°ia √∫rove≈à m√° najni≈æ≈°ie rozl√≠≈°enie (downsampling).
    - Najni≈æ≈°ia √∫rove≈à m√° p√¥vodn√© rozl√≠≈°enie.
  - Na ka≈ædej √∫rovni sa vykon√° segment√°cia.
  - V√Ωsledky z vy≈°≈°√≠ch √∫rovn√≠ sa pou≈æij√∫ na usmernenie segment√°cie na ni≈æ≈°√≠ch √∫rovniach.
- **Pr√≠klad:** 
  - Pri vyhƒæad√°van√≠ veƒæk√Ωch objektov sa pou≈æij√∫ vy≈°≈°ie √∫rovne (n√≠zke rozl√≠≈°enie).
  - Pri detailnom vyhƒæad√°van√≠ men≈°√≠ch ƒçast√≠ sa pou≈æij√∫ ni≈æ≈°ie √∫rovne (vysok√© rozl√≠≈°enie).

---

Tento prehƒæad obsahuje teoretick√© z√°klady aj praktick√© pr√≠klady, ktor√© ti pom√¥≈æu pri sk√∫≈°ke. Ak potrebuje≈° prepoƒç√≠ta≈• konkr√©tny algoritmus alebo pr√≠klady k√≥du, staƒç√≠ da≈• vedie≈•. üòä

10. OTAZKA: Oznaƒçovanie spojen√Ωch komponentov, uveƒète pr√≠klad algoritmu. Morfologick√© oper√°cie, dilat√°cia a er√≥zia (≈°trukt√∫rny element, krit√©ri√° hit a fit), otvorenie a uzavretie, transform√°cia hit-or-miss, vzdialenostn√° transform√°cia, skeletoniz√°cia, princ√≠p segment√°cie pomocou rozvodia, ≈°edot√≥nov√° er√≥zia a dilat√°cia, oddelenie pozadia pomocou ≈°edot√≥novej er√≥zie

### **Oznaƒçovanie spojen√Ωch komponentov**

Oznaƒçovanie spojen√Ωch komponentov (Connected Component Labeling, CCL) je met√≥da na identifik√°ciu a oznaƒçovanie s√∫visl√Ωch oblast√≠ v bin√°rnom obraze. Pou≈æ√≠va sa v anal√Ωze obrazov na segment√°ciu a identifik√°ciu objektov.

1. **Algoritmus na oznaƒçovanie spojen√Ωch komponentov (2-pass algoritmus):**
   - Predpoklad√°me bin√°rny obraz, kde 1 oznaƒçuje pixely patriace k objektu a 0 pozadie.
   - Pou≈æ√≠va 4-susednos≈• alebo 8-susednos≈•.

   **Kroky:**
   1. **Priechod 1:**
      - Prech√°dzame obraz pixel po pixeli.
      - Ak je pixel s√∫ƒças≈•ou objektu (hodnota 1):
        - Skontrolujeme jeho susedov (v z√°vislosti od susednosti, napr. 4-susednos≈• kontroluje horn√©ho a ƒæav√©ho suseda).
        - Ak maj√∫ susedia u≈æ priraden√© znaƒçky, pixel dostane najmen≈°iu z t√Ωchto znaƒçiek.
        - Ak nem√° ≈æiadny sused znaƒçku, pixel dostane nov√∫ znaƒçku.
        - Zaznamen√°vame ekvivalencie medzi znaƒçkami (ak r√¥zni susedia maj√∫ r√¥zne znaƒçky).
   2. **Priechod 2:**
      - V≈°etky pixely s ekvivalentn√Ωmi znaƒçkami sa aktualizuj√∫ na rovnak√∫ koneƒçn√∫ znaƒçku.
   3. **V√Ωstup:**
      - Ka≈æd√° s√∫visl√° oblas≈• v obraze m√° jedineƒçn√∫ znaƒçku.

   **Pr√≠klad:**
   Bin√°rny obraz:
   ```
   0 1 1 0
   1 1 0 0
   0 0 1 1
   0 1 1 0
   ```
   Po aplikovan√≠ algoritmu (4-susednos≈•):
   ```
   0 1 1 0
   1 1 0 0
   0 0 2 2
   0 2 2 0
   ```

---

### **Morfologick√© oper√°cie**

Morfologick√© oper√°cie sa pou≈æ√≠vaj√∫ na spracovanie bin√°rnych alebo ≈°edot√≥nov√Ωch obrazov. Vyu≈æ√≠vaj√∫ **≈°trukt√∫rny element (SE)**, ktor√Ω definuje sp√¥sob interakcie s obrazom.

#### **1. Dilat√°cia:**
- Roz≈°iruje objekty v obraze, prid√°va pixely k hran√°m objektu.
- **Hit krit√©rium:** ≈†trukt√∫rny element sa mus√≠ aspo≈à ƒçiastoƒçne prekr√Ωva≈• s objektom.
- **Vzorec (bin√°rne obrazy):**  
  \( A \oplus B = \{ z \mid (B_z \cap A) \neq \emptyset \} \)

#### **2. Er√≥zia:**
- Zmen≈°uje objekty v obraze, odstra≈àuje pixely na hran√°ch objektu.
- **Fit krit√©rium:** ≈†trukt√∫rny element sa mus√≠ √∫plne vojs≈• do objektu.
- **Vzorec (bin√°rne obrazy):**  
  \( A \ominus B = \{ z \mid B_z \subseteq A \} \)

#### **3. Otvorenie (Opening):**
- Sekvencia er√≥zie a dilat√°cie.
- Pou≈æ√≠va sa na odstr√°nenie ≈°umu a mal√Ωch objektov.
- \( A \circ B = (A \ominus B) \oplus B \)

#### **4. Uzavretie (Closing):**
- Sekvencia dilat√°cie a er√≥zie.
- Pou≈æ√≠va sa na vyplnenie medzier a sp√°janie objektov.
- \( A \bullet B = (A \oplus B) \ominus B \)

---

### **Transform√°cia hit-or-miss**
- Identifikuje konkr√©tne tvarov√© vzory v obraze.
- Vyu≈æ√≠va **≈°trukt√∫rny element** \( B \) pozost√°vaj√∫ci z dvoch ƒçast√≠:
  - Oblas≈•, ktor√° mus√≠ obsahova≈• objekt.
  - Oblas≈•, ktor√° mus√≠ by≈• pozad√≠m.
- **Vzorec:**  
  \( A \otimes B = (A \ominus B_1) \cap (A^c \ominus B_2) \), kde \( B_1 \) je objektov√° a \( B_2 \) pozadov√° ƒças≈• SE.

---

### **Vzdialenostn√° transform√°cia**
- Pre ka≈æd√Ω pixel v obraze vypoƒç√≠ta vzdialenos≈• k najbli≈æ≈°iemu pixelu pozadia.
- Pou≈æ√≠va sa na:
  - N√°vrh ≈°trukt√∫r.
  - Skeletoniz√°ciu.
  - Segment√°ciu pomocou rozvodia.
- Pr√≠klad metriky: **Euklidovsk√° vzdialenos≈•**, **Manhattansk√° vzdialenos≈•**.

---

### **Skeletoniz√°cia**
- Zredukuje objekty na ich kostru (jednobunkov√∫ hr√∫bku), priƒçom zachov√° ich topol√≥giu.
- Pou≈æitie: Rekon≈°trukcia tvarov, anal√Ωza tvarov√Ωch vlastnost√≠.

---

### **Princ√≠p segment√°cie pomocou rozvodia**
- Modeluje obraz ako topografick√∫ mapu:
  - Jas predstavuje v√Ω≈°ku.
- Simuluje zaplavenie:
  - Voda teƒçie z minima smerom k maxim√°m.
  - Oblasti, ktor√© sa zaplavuj√∫ z r√¥znych minim, sa oddelia ‚Äûhradn√Ωmi m√∫rmi‚Äú.
- Pou≈æ√≠va sa na segment√°ciu objektov na z√°klade hraniƒçn√Ωch hodn√¥t.

---

### **≈†edot√≥nov√° er√≥zia a dilat√°cia**
1. **≈†edot√≥nov√° dilat√°cia:**
   - Nahrad√≠ pixel maxim√°lnou hodnotou v jeho okol√≠ definovanom ≈°trukt√∫rnym elementom.
2. **≈†edot√≥nov√° er√≥zia:**
   - Nahrad√≠ pixel minim√°lnou hodnotou v jeho okol√≠ definovanom ≈°trukt√∫rnym elementom.

---

### **Oddelenie pozadia pomocou ≈°edot√≥novej er√≥zie**
- Pou≈æitie: Identifik√°cia objektov na pozad√≠.
- Postup:
  - Aplikujeme ≈°edot√≥nov√∫ er√≥ziu na obraz.
  - Pozadie sa ‚Äûodstr√°ni‚Äú, preto≈æe sa zn√≠≈æia hodnoty intenzity.

---

Tento obsah obsahuje kƒæ√∫ƒçov√© koncepty, vzorce a pr√≠klady potrebn√© na pochopenie t√©my a pr√≠pravu na sk√∫≈°ku. Ak potrebuje≈° viac detailov alebo k√≥dov√© implement√°cie, daj vedie≈•! üòä

11 OTAZKA: Rozpozn√°vanie objektov, jednoduch√© skal√°rne deskriptory oblast√≠, klasifik√°tory, pravidlov√Ω klasifik√°tor, diskriminat√≠vne a generat√≠vne met√≥dy rozpozn√°vania, Bayesovo pravidlo a naivn√Ω Bayesov klasifik√°tor

Priprav√≠m pre v√°s komplexn√∫ odpoveƒè, ktor√° v√°m pom√¥≈æe pripravi≈• sa na sk√∫≈°ku. Rozoberiem ka≈æd√∫ ƒças≈• podrobne:

1. Rozpozn√°vanie objektov:
- Je to proces urƒçovania, ƒçi obrazov√© d√°ta obsahuj√∫ ≈°pecifick√Ω objekt, vlastnos≈• alebo aktivitu
- Del√≠ sa na:
  - Objektov√© rozpozn√°vanie (klasifik√°cia) - rozpozn√°vanie jedn√©ho alebo viacer√Ωch nauƒçen√Ωch objektov vr√°tane ich 2D poz√≠cie v obraze alebo 3D p√≥zy
  - Identifik√°cia - rozpozn√°vanie konkr√©tnej in≈°tancie objektu (napr. konkr√©tna tv√°r osoby, odtlaƒçok prsta)
  - Detekcia - skenovanie obrazu pre ≈°pecifick√© podmienky (napr. abnorm√°lne bunky v medic√≠nskych sn√≠mkach)

2. Jednoduch√© skal√°rne deskriptory oblast√≠:
- Veƒækos≈•/Plocha (Area):
  - Poƒçet pixelov vn√∫tri oblasti
  - Pri polyg√≥ne sa d√° vypoƒç√≠ta≈• zo s√∫radn√≠c vrcholov

- Obvod (Perimeter):
  - S√∫ƒçet Euklidovsk√Ωch vzdialenost√≠ obrysov√Ωch bodov pozdƒ∫≈æ kont√∫ry

- Okr√∫hlos≈• (Roundness):
  - Vzorec: (4 √ó œÄ √ó plocha) / obvod¬≤
  - Hodnoty v intervale <0,1>, kde 1.0 predstavuje dokonal√Ω kruh

- Feretov priemer:
  - Priemer kruhu s rovnakou plochou ako sledovan√Ω objekt

- Dƒ∫≈æka hlavnej osi:
  - Najdlh≈°ia √∫seƒçka medzi dvoma ƒæubovoƒæn√Ωmi bodmi obvodu

- Eulerovo ƒç√≠slo:
  - E = S - N (S = poƒçet s√∫visl√Ωch objektov, N = poƒçet dier)
  - Popisuje topol√≥giu objektu

3. Pravidlov√Ω klasifik√°tor:
Pr√≠klad jednoduch√Ωch pravidiel:
```
Ak (Okr√∫hlos≈• > 0.9 AND Plocha > 50) potom Objekt = Jablko
inak Ak (Okr√∫hlos≈• > 0.7 AND Plocha > 50) potom Objekt = Hru≈°ka
inak Ak (Okr√∫hlos≈• < 0.7 AND Plocha < 30) potom Objekt = Slivka
inak Objekt = Nezn√°my
```

4. Diskriminat√≠vne met√≥dy rozpozn√°vania:
- Pracuj√∫ v priestore pr√≠znakov (N-rozmernom)
- Vytv√°raj√∫ model urƒçuj√∫ci hranicu medzi triedami (diskriminaƒçn√° funkcia)
- Potrebuj√∫ pr√≠klady aspo≈à dvoch tried
- Pr√≠klady met√≥d:
  - Umel√© neur√≥nov√© siete (ANN)
  - Support Vector Machines (SVM)
  - Rozhodovacie stromy
  - Line√°rna regresia

5. Generat√≠vne met√≥dy rozpozn√°vania:
- Model vymedzuje hranice jednotliv√Ωch tried
- Dok√°≈æu generova≈• nov√© pr√≠klady danej triedy
- Staƒçia pr√≠klady jednej triedy
- Pr√≠klad: Naivn√Ω Bayesov klasifik√°tor

6. Bayesovo pravidlo:
- P(A|B) = P(B|A) √ó P(A) / P(B)
- Praktick√Ω pr√≠klad z predn√°≈°ky (drogov√Ω test):
  - Citlivos≈• testu: 90%
  - ≈†pecifickos≈•: 95%
  - Prevalencia: 5%
  - V√Ωpoƒçet pravdepodobnosti u≈æ√≠vania drog pri pozit√≠vnom teste:
    P(beriem|pozit. test) = 0.9 √ó 0.05 / (0.05 √ó 0.9 + 0.05 √ó 0.95) = 0.486 (48.6%)

7. Naivn√Ω Bayesov klasifik√°tor:
- Predpoklady:
  - Pr√≠znaky s√∫ navz√°jom nez√°visl√©
  - Hodnoty pr√≠znakov maj√∫ norm√°lne rozdelenie pravdepodobnosti

Pr√≠klad klasifik√°cie:
- M√°me d√°tov√∫ mno≈æinu s pr√≠znakmi (napr. okr√∫hlos≈•) a triedami (jablko, hru≈°ka)
- Pre nov√Ω objekt s okr√∫hlos≈•ou 0.88:
  1. Vypoƒç√≠tame P(jablko) a P(hru≈°ka) z tr√©novac√≠ch d√°t
  2. Aproximujeme rozdelenie pr√≠znakov pomocou Gaussov√Ωch kriviek
  3. Vypoƒç√≠tame P(okr√∫hlos≈• = 0.88|jablko) a P(okr√∫hlos≈• = 0.88|hru≈°ka)
  4. Pomocou Bayesovho pravidla urƒç√≠me pravdepodobnosti tried
  5. Klasifikujeme podƒæa vy≈°≈°ej pravdepodobnosti

D√¥le≈æit√© pozn√°mky pre sk√∫≈°ku:
- Vedie≈• vysvetli≈• rozdiely medzi diskriminat√≠vnymi a generat√≠vnymi met√≥dami
- Pozna≈• z√°kladn√© skal√°rne deskriptory a vedie≈• ich vypoƒç√≠ta≈•
- Rozumie≈• Bayesovmu pravidlu a vedie≈• ho aplikova≈• na praktick√© pr√≠klady
- Ch√°pa≈• princ√≠p naivn√©ho Bayesovho klasifik√°tora a jeho predpoklady
- Vedie≈• navrhn√∫≈• jednoduch√Ω pravidlov√Ω klasifik√°tor pre konkr√©tny probl√©m

12 OTAZKA : Z√°kladn√Ω princ√≠p fungovania met√≥dy Violu-Jonesa, Haarova ƒçrta, sp√°janie v√Ωstupov viacer√Ωch Haarov√Ωch ƒç≈ït, pr√≠klad pre detekciu tv√°r√≠. Z√°kladn√Ω popis fungovania SIFT, ƒço s√∫ to ƒçrty - kƒæ√∫ƒçov√© body, deskriptor, ≈°k√°lov√° a rotaƒçn√° invariancia, n√°ƒçrt ako funguje klasifik√°cia objektu.

Priprav√≠m komplexn√© vysvetlenie t√Ωchto d√¥le≈æit√Ωch met√≥d poƒç√≠taƒçov√©ho videnia:

1. MET√ìDA VIOLA-JONES
Z√°kladn√Ω princ√≠p:
- Framework navrhnut√Ω v roku 2001 pre detekciu objektov v re√°lnom ƒçase
- Prim√°rne urƒçen√Ω na detekciu tv√°r√≠, ale pou≈æiteƒæn√Ω aj pre in√© objekty
- Pozost√°va zo 4 hlavn√Ωch f√°z:

A) Haarove ƒçrty (Haar Features):
- S√∫ to jednoduch√© obdƒ∫≈ænikov√© filtre pozost√°vaj√∫ce z ƒçiernych a bielych oblast√≠
- Hodnota ƒçrty sa poƒç√≠ta ako rozdiel s√∫m pixelov pod bielymi a ƒçiernymi oblas≈•ami
- Pr√≠klady Haarov√Ωch ƒç≈ït pre detekciu tv√°r√≠:
  - Horizont√°lna ƒçrta pre detekciu oƒç√≠ (tmav≈°ia oblas≈• medzi svetlej≈°√≠mi)
  - Vertik√°lna ƒçrta pre detekciu nosa
  - Diagon√°lne ƒçrty pre detekciu l√≠c

B) Integr√°lny obraz:
- Efekt√≠vny sp√¥sob v√Ωpoƒçtu s√∫m pixelov v obdƒ∫≈ænikov√Ωch oblastiach
- Pre ka≈æd√Ω bod (x,y) obsahuje sumu v≈°etk√Ωch pixelov nad a naƒæavo
- Umo≈æ≈àuje r√Ωchly v√Ωpoƒçet Haarov√Ωch ƒç≈ït pomocou 4 pr√≠stupov do pam√§te

C) AdaBoost tr√©ning:
- Kombinuje mnoho "slab√Ωch" klasifik√°torov do jedn√©ho siln√©ho
- Ka≈æd√Ω slab√Ω klasifik√°tor pou≈æ√≠va jednu Haarovu ƒçrtu
- V√°≈æi klasifik√°tory podƒæa ich √∫spe≈°nosti
- V√Ωsledn√Ω siln√Ω klasifik√°tor je v√°≈æenou sumou slab√Ωch klasifik√°torov

D) Kask√°dov√© klasifik√°tory:
- Usporiadanie klasifik√°torov do kask√°dy (postupnosti)
- Zaƒç√≠na jednoduch≈°√≠mi klasifik√°tormi
- Ak regi√≥n neprejde cez aktu√°lny stupe≈à, je okam≈æite zamietnut√Ω
- Ak prejde, pokraƒçuje na ƒèal≈°√≠ stupe≈à
- Zr√Ωchƒæuje detekciu t√Ωm, ≈æe r√Ωchlo eliminuje oblasti bez tv√°re

2. SIFT (Scale Invariant Feature Transform)
Z√°kladn√Ω princ√≠p:
- Vyvinut√Ω Davidom Lowem v 1999
- Detekuje a popisuje lok√°lne ƒçrty v obrazoch
- Invariantn√Ω voƒçi ≈°k√°le, rot√°cii a ƒçiastoƒçne voƒçi zmene osvetlenia

A) Kƒæ√∫ƒçov√© body (Keypoints):
- V√Ωznamn√© body v obraze (rohy, hrany, v√Ωrazn√© text√∫ry)
- Detekcia v r√¥znych ≈°k√°lach pomocou Difference of Gaussian (DoG)
- V√Ωber stabiln√Ωch bodov, ktor√© sa zachov√°vaj√∫ pri transform√°ci√°ch

B) Deskriptor:
- 128-dimenzion√°lny vektor popisuj√∫ci okolie kƒæ√∫ƒçov√©ho bodu
- Zalo≈æen√Ω na histogramoch gradientov
- Rozdelenie okolia na 4√ó4 oblasti
- V ka≈ædej oblasti 8 smerov√Ωch histogramov

C) ≈†k√°lov√° invariancia:
- Dosiahnut√° vytvoren√≠m scale-space pyram√≠dy
- Detekcia kƒæ√∫ƒçov√Ωch bodov vo v≈°etk√Ωch ≈°k√°lach
- Automatick√Ω v√Ωber charakteristickej ≈°k√°ly pre ka≈æd√Ω bod

D) Rotaƒçn√° invariancia:
- V√Ωpoƒçet dominantnej orient√°cie pre ka≈æd√Ω kƒæ√∫ƒçov√Ω bod
- Deskriptor je normalizovan√Ω vzhƒæadom na t√∫to orient√°ciu

E) Klasifik√°cia objektu pomocou SIFT:
1. Detekcia kƒæ√∫ƒçov√Ωch bodov v tr√©novacej aj testovacej sn√≠mke
2. V√Ωpoƒçet deskriptorov pre v≈°etky kƒæ√∫ƒçov√© body
3. P√°rovanie zodpovedaj√∫cich bodov medzi sn√≠mkami
4. Pou≈æitie zov≈°eobecnenej Houghovej transform√°cie na potvrdenie zhody
5. V√Ωpoƒçet afinn√Ωch transform√°ci√≠ objektu

Hlavn√© v√Ωhody SIFT:
- Robustnos≈• voƒçi zmene mierky a rot√°cii
- ƒåiastoƒçn√° invariancia voƒçi zmene osvetlenia
- Rozpozn√°vanie ƒçiastoƒçne prekryt√Ωch objektov
- Vysok√° presnos≈• p√°rovania ƒç≈ït

Mo≈æn√© aplik√°cie:
- Rozpozn√°vanie objektov
- Sledovanie objektov vo videu
- Panoramatick√© sp√°janie sn√≠mok
- 3D rekon≈°trukcia sc√©ny
- Vizu√°lna lokaliz√°cia robotov

13 OTAZKA: Houghova transform√°cia, kompletn√Ω popis met√≥dy pre vyhƒæad√°vanie priamok, popis modifik√°cie pre detekciu kru≈æn√≠c, praktick√© pou≈æitie
Priprav√≠m komplexn√© vysvetlenie Houghovej transform√°cie:

1. Z√ÅKLADN√ù PRINC√çP HOUGHOVEJ TRANSFORM√ÅCIE PRE PRIAMKY

A) Transform√°cia z priestoru obrazu do parametrick√©ho priestoru:
- Ka≈æd√Ω bod (x,y) v obraze m√¥≈æe le≈æa≈• na nekoneƒçne mnoho priamok
- Priamka je definovan√° rovnicou: y = mx + b
- Alternat√≠vna parametriz√°cia (pou≈æ√≠vanej≈°ia): œÅ = x¬∑cos(Œ∏) + y¬∑sin(Œ∏)
  kde: œÅ - kolm√° vzdialenos≈• priamky od poƒçiatku
       Œ∏ - uhol medzi kolmicou na priamku a osou x

B) Postup detekcie:
1. Vytvorenie akumul√°tora (2D pole) pre parametre (œÅ,Œ∏)
2. Pre ka≈æd√Ω hranov√Ω bod (x,y) v obraze:
   - Pre ka≈æd√Ω uhol Œ∏ vypoƒç√≠ta≈• œÅ
   - Inkrementova≈• hodnotu v akumul√°tore na poz√≠cii (œÅ,Œ∏)
3. Hƒæadanie lok√°lnych max√≠m v akumul√°tore
   - Maxima reprezentuj√∫ najpravdepodobnej≈°ie priamky v obraze

Pr√≠klad implement√°cie pre priamky:
```python
def hough_transform_lines(edge_image):
    height, width = edge_image.shape
    diagonal = np.ceil(np.sqrt(height**2 + width**2))
    rhos = np.linspace(-diagonal, diagonal, 2*diagonal)
    thetas = np.deg2rad(np.arange(-90, 90))
    
    # Vytvorenie akumul√°tora
    accumulator = np.zeros((len(rhos), len(thetas)))
    
    # S√∫radnice hranov√Ωch bodov
    y_idxs, x_idxs = np.nonzero(edge_image)
    
    # Hlasovanie
    for i in range(len(x_idxs)):
        x = x_idxs[i]
        y = y_idxs[i]
        for theta_idx in range(len(thetas)):
            theta = thetas[theta_idx]
            rho = x*np.cos(theta) + y*np.sin(theta)
            rho_idx = np.argmin(np.abs(rhos-rho))
            accumulator[rho_idx, theta_idx] += 1
            
    return accumulator, rhos, thetas
```

2. MODIFIK√ÅCIA PRE DETEKCIU KRU≈ΩN√çC

A) Princ√≠p:
- Kru≈ænica je definovan√° troma parametrami: (x‚ÇÄ, y‚ÇÄ, r)
  kde: (x‚ÇÄ,y‚ÇÄ) - stred kru≈ænice
       r - polomer
- Parametrick√° rovnica: (x - x‚ÇÄ)¬≤ + (y - y‚ÇÄ)¬≤ = r¬≤

B) Postup detekcie:
1. Vytvorenie 3D akumul√°tora pre parametre (x‚ÇÄ,y‚ÇÄ,r)
2. Pre ka≈æd√Ω hranov√Ω bod (x,y):
   - Pre ka≈æd√Ω mo≈æn√Ω polomer r:
     - Vypoƒç√≠ta≈• mo≈æn√© stredy kru≈ænice
     - Inkrementova≈• hodnoty v akumul√°tore
3. N√°js≈• lok√°lne maxim√° v 3D akumul√°tore

Pr√≠klad implement√°cie pre kru≈ænice:
```python
def hough_transform_circles(edge_image, r_min, r_max):
    height, width = edge_image.shape
    accumulator = np.zeros((height, width, r_max - r_min))
    
    # S√∫radnice hranov√Ωch bodov
    y_idxs, x_idxs = np.nonzero(edge_image)
    
    # Hlasovanie
    for i in range(len(x_idxs)):
        x = x_idxs[i]
        y = y_idxs[i]
        for r in range(r_min, r_max):
            for theta in np.linspace(0, 2*np.pi, 100):
                x0 = x - r*np.cos(theta)
                y0 = y - r*np.sin(theta)
                if 0 <= x0 < width and 0 <= y0 < height:
                    accumulator[int(y0), int(x0), r-r_min] += 1
                    
    return accumulator
```

3. PRAKTICK√â POU≈ΩITIE

A) Predspracovanie obrazu:
- Konverzia na odtiene ≈°edej
- Detekcia hr√°n (napr. Cannyho detektor)
- Redukcia ≈°umu (napr. Gaussov filter)

B) Optimaliz√°cie:
- Obmedzenie rozsahu parametrov
- Prahov√© hodnoty pre akumul√°tor
- Lok√°lne maximum s okol√≠m

C) Aplik√°cie:
- Detekcia ƒçiar na cest√°ch
- Rozpozn√°vanie dopravn√Ωch znaƒçiek
- Detekcia objektov v priemysle
- Anal√Ωza medic√≠nskych sn√≠mok
- Detekcia minc√≠ a kruhov√Ωch objektov

D) V√Ωhody:
- Robustnos≈• voƒçi ≈°umu
- Detekcia preru≈°ovan√Ωch ƒçiar
- Mo≈ænos≈• detekcie viacer√Ωch objektov naraz

E) Nev√Ωhody:
- V√Ωpoƒçtov√° n√°roƒçnos≈•
- Pam√§≈•ov√° n√°roƒçnos≈• pre 3D akumul√°tor
- Citlivos≈• na voƒæbu parametrov

Pr√≠klad kompletn√©ho pou≈æitia:
```python
def detect_lines_and_circles(image):
    # Predspracovanie
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    
    # Detekcia priamok
    lines_accumulator, rhos, thetas = hough_transform_lines(edges)
    lines = find_peaks_in_accumulator(lines_accumulator, threshold=100)
    
    # Detekcia kru≈æn√≠c
    circles_accumulator = hough_transform_circles(edges, r_min=20, r_max=100)
    circles = find_peaks_in_3d_accumulator(circles_accumulator, threshold=50)
    
    return lines, circles
```

Tieto poznatky s√∫ d√¥le≈æit√© pre sk√∫≈°ku a praktick√© pou≈æitie v poƒç√≠taƒçovom viden√≠. Odpor√∫ƒçam porozumie≈•:
- Princ√≠pu transform√°cie priestorov
- Rozdielu medzi detekciou priamok a kru≈æn√≠c
- Optimaliz√°ci√°m a praktick√Ωm aspektom implement√°cie
- Mo≈ænostiam vyu≈æitia v re√°lnych aplik√°ci√°ch

14 OTAZKA: D√¥vody anal√Ωzy pohybu v obraze, predpoklady ur√Ωchƒæuj√∫ce anal√Ωzu pohybu, diferenci√°lna met√≥da, kumulat√≠vny diferenƒçn√Ω obraz, modelovanie pozadia, motion field a optick√Ω tok (v ƒçom je rozdiel), optick√Ω tok pomocou sledovania ƒç≈ït.

Na z√°klade pridanej predn√°≈°ky priprav√≠m aktualizovan√∫ a presn√∫ odpoveƒè:

1. D√îVODY ANAL√ùZY POHYBU V OBRAZE
- Detekcia pohybu v bezpeƒçnostn√Ωch syst√©moch
- Sledovanie objektov (object tracking)
- Segment√°cia pohybuj√∫cich sa objektov
- Rekon≈°trukcia 3D tvaru z pohybu (structure from motion)
- Roz≈°√≠ren√° realita (augmented reality)
- Riadenie dopravy
- Medic√≠nske zobrazovanie
- Kompresia videa

2. PREDPOKLADY UR√ùCHƒΩUJ√öCE ANAL√ùZU POHYBU
- Jas ka≈æd√©ho pixelu je kon≈°tantn√Ω v ƒçase (Brightness constancy)
- Body v okol√≠ pohybuj√∫ceho sa pixelu sa pohybuj√∫ podobne (Spatial coherence)
- Sc√©na m√¥≈æe by≈•:
  - Statick√° kamera, pohybuj√∫ce sa objekty
  - Statick√° sc√©na, pohybuj√∫ca sa kamera
  - Kombin√°cia oboch

3. DIFERENCI√ÅLNA MET√ìDA
- Zalo≈æen√° na rozdieloch medzi po sebe nasleduj√∫cimi sn√≠mkami
- Detekuje zmeny na √∫rovni pixelov
- ƒåasto pou≈æ√≠van√° v aplik√°ci√°ch dohƒæadu
- Modifik√°cia: diferencia v hranovom obraze
  - Kombinuje diferenƒçn√Ω obraz D(i,j) s obrazom hr√°n S(i,j)
  - Hrany sa z√≠skaj√∫ hranov√Ωch detektorom
  - Pou≈æitie oper√°cie AND pre premietnutie hr√°n

4. KUMULAT√çVNY DIFERENƒåN√ù OBRAZ (ADI - Accumulative Difference Image)
- Akumuluje rozdiely medzi sn√≠mkami v ƒçase
- Zachyt√°va hist√≥riu pohybu v sc√©ne
- U≈æitoƒçn√Ω pre anal√Ωzu dlhodobej≈°√≠ch zmien

5. MODELOVANIE POZADIA
Algoritmus pomocou medi√°nov√©ho filtra:
1. Inicializ√°cia: Sn√≠manie K sn√≠mkov, v√Ωpoƒçet medi√°novej intenzity pre ka≈æd√Ω pixel
2. Sn√≠manie ƒèal≈°ieho obrazu a v√Ωpoƒçet rozdielu s medi√°novou hodnotou
3. Prahovanie pre minimaliz√°ciu ≈°umu
4. Filtrovanie a morfologick√© oper√°cie pre odstr√°nenie ≈°umu
5. Prepoƒç√≠tanie medi√°nu so zahrnut√≠m nov√Ωch pixelov pozadia
6. Opakovanie procesu

6. MOTION FIELD VS OPTICK√ù TOK

Motion Field:
- Ide√°lna reprezent√°cia 3D pohybu premietnut√©ho do roviny kamery
- Z√°vis√≠ na konkr√©tnych bodoch v priestore
- ƒåasov√° deriv√°cia poz√≠cie v≈°etk√Ωch bodov obrazu zodpovedaj√∫cich fixn√Ωm 3D bodom

Optick√Ω tok (Optical Flow):
- Zalo≈æen√Ω na porovn√°van√≠ zmien jasu v kr√°tkom ƒçasovom intervale
- Z√°vis√≠ na zmene jasu v obraze
- Podmienky:
  - Kon≈°tantn√Ω jas pixelu v ƒçase
  - Podobn√Ω pohyb bodov v okol√≠

Hlavn√Ω rozdiel:
- Motion field z√°vis√≠ na skutoƒçnom pohybe bodov
- Optick√Ω tok z√°vis√≠ na zmen√°ch jasu v obraze
- Nemusia by≈• v≈ædy toto≈æn√© (napr√≠klad pri rotuj√∫cej guli s jednotnou text√∫rou)

7. OPTICK√ù TOK POMOCOU SLEDOVANIA ƒå≈îT
- Zalo≈æen√Ω na detekcii a sledovan√≠ v√Ωznamn√Ωch bodov v obraze
- Proces:
  1. Detekcia v√Ωznamn√Ωch bodov (ƒç≈ït)
  2. Sledovanie t√Ωchto bodov medzi sn√≠mkami
  3. V√Ωpoƒçet vektorov pohybu
- Vyu≈æitie napr√≠klad v:
  - Medic√≠nskom zobrazovan√≠ (anal√Ωza pohybu org√°nov)
  - Sledovan√≠ objektov
  - Anal√Ωze pohybu v sc√©ne

Praktick√© aspekty:
- Potreba rie≈°i≈• probl√©my so ≈°umom
- Spr√°vne nastavenie parametrov detekcie
- Optimaliz√°cia v√Ωpoƒçtovej n√°roƒçnosti
- Rie≈°enie prekr√Ωvaj√∫cich sa objektov

15 OTAZKA Vysvetlenie princ√≠pu pas√≠vnej stereov√≠zie pre kamery s paraleln√Ωmi optick√Ωmi osami, block matching algoritmus pri v√Ωpoƒçte disparity, met√≥dy urƒçovania podobnosti blokov pri block matchingu, vz≈•ah disparity a vzdialenosti bodu od kamery. ƒåo je to epipol√°rne obmedzenie, epipol√°rne l√≠nie. Probl√©my pri hƒæadan√≠ zhody (stereo-kore≈°pondencie) pri pas√≠vnej sterov√≠zii. Pr√≠klady met√≥d z√≠skania 3D obrazu: akt√≠vna stereov√≠zia, LiDAR, ToF kamera

Na z√°klade predn√°≈°ky priprav√≠m odpoveƒè zameran√∫ na stereov√≠ziu a 3D sn√≠manie:

1. Z√çSKANIE TRETIEHO ROZMERU (V≈†EOBECN√â MET√ìDY)
- Kombin√°cia dvoch pohƒæadov (stereo videnie)
- S√©riov√© rezy kolm√© na os Z
- Pou≈æitie hƒ∫bkomerov (akt√≠vne, pas√≠vne)
- ≈†peci√°lne usporiadanie zdroja svetla a sn√≠maƒça
- Kombin√°cia obrazov z r√¥znych uhlov (CT)

2. PAS√çVNA STEREOV√çZIA S PARALELN√ùMI KAMERAMI

A) Princ√≠p:
- Vyu≈æ√≠va dve kamery s paraleln√Ωmi optick√Ωmi osami
- Rozdiel v poz√≠cii objektu na sn√≠mkach z dvoch kamier (disparita)
- ƒå√≠m je objekt bli≈æ≈°ie, t√Ωm v√§ƒç≈°ia disparita

B) Block Matching algoritmus:
- Rozdelenie obrazu na bloky
- Hƒæadanie zodpovedaj√∫cich blokov v druhom obraze
- V√Ωpoƒçet disparity pre ka≈æd√Ω blok

C) Met√≥dy urƒçovania podobnosti blokov:
- Sum of Absolute Differences (SAD)
- Sum of Squared Differences (SSD)
- Normalized Cross-Correlation (NCC)
- Census transform
- Rank transform

D) Vz≈•ah disparity a vzdialenosti:
- Z = (f √ó B) / d
  kde: Z - vzdialenos≈• bodu
       f - ohniskov√° vzdialenos≈•
       B - vzdialenos≈• medzi kamerami (baseline)
       d - disparita

3. EPIPOL√ÅRNA GEOMETRIA

A) Epipol√°rne obmedzenie:
- Zjednodu≈°uje hƒæadanie kore≈°pondenci√≠
- Bod v jednom obraze le≈æ√≠ na epipol√°rnej l√≠nii v druhom obraze

B) Epipol√°rne l√≠nie:
- Prieseƒçn√≠ky epipol√°rnej roviny s obrazov√Ωmi rovinami
- Pri paraleln√Ωch kamer√°ch s√∫ horizont√°lne
- Redukuj√∫ 2D probl√©m hƒæadania na 1D

4. PROBL√âMY PRI HƒΩADAN√ç STEREO-KORE≈†PONDENCIE

A) Z√°kladn√© probl√©my:
- Okl√∫zie (ƒçasti viditeƒæn√© len z jednej kamery)
- Opakuj√∫ce sa vzory
- Homog√©nne oblasti
- Perspekt√≠vne skreslenie
- Rozdielne osvetlenie v obrazoch

5. ALTERNAT√çVNE MET√ìDY Z√çSKANIA 3D OBRAZU

A) Akt√≠vna stereov√≠zia:
- Projekcia zn√°meho vzoru (structured light)
- Anal√Ωza deform√°cie vzoru na povrchu
- Pr√≠klad: Kinect (kombinuje structured light s:
  - depth from focus
  - depth from stereo)

B) LiDAR (Light Detection and Ranging):
- Meranie vzdialenosti pomocou laseru
- Anal√Ωza odrazen√©ho svetla
- Mo≈ænos≈• 2D alebo 3D skenovania
- Vyu≈æitie: auton√≥mne vozidl√°, mapovanie ter√©nu

C) ToF (Time of Flight) kamera:
- Meranie ƒçasu letu sveteln√©ho pulzu
- Cel√° sc√©na zachyten√° naraz (scannerless)
- Pr√≠klad: Intel RealSense
- Princ√≠p:
  1. Vyslanie kr√°tkeho sveteln√©ho pulzu
  2. Meranie ƒçasu n√°vratu odrazen√©ho svetla
  3. V√Ωpoƒçet vzdialenosti na z√°klade oneskorenia

PRAKTICK√â ASPEKTY:
- Kalibr√°cia kamier
- Spracovanie ≈°umu
- V√Ωpoƒçtov√° n√°roƒçnos≈•
- Presnos≈• merania
- Vplyv okolit√©ho osvetlenia

D√¥le≈æit√© pre sk√∫≈°ku:
1. Pochopi≈• princ√≠p v√Ωpoƒçtu disparity
2. Vedie≈• vysvetli≈• epipol√°rne obmedzenie
3. Pozna≈• probl√©my stereo-kore≈°pondencie
4. Rozumie≈• rozdielom medzi akt√≠vnymi a pas√≠vnymi met√≥dami
5. Vedie≈• vysvetli≈• princ√≠py r√¥znych 3D zobrazovac√≠ch met√≥d

16 OTAZKA Text√∫ry, charakteristika a rozdelenie, ≈°k√°lov√° z√°vislos≈•, text√∫rny element, text√∫rny gradient. ≈†trukt√∫rny, fourierovsk√Ω a ≈°tatistick√Ω pr√≠stup ku anal√Ωze text√∫r, v ƒçom spoƒç√≠vaj√∫. Lawsove text√∫rne masky. V√Ωpoƒçet kookurenƒçnej matice, krit√©ri√° odvoden√© z kookurenƒçnej matice a ich pou≈æitie na klasifik√°ciu text√∫r, pr√≠klad klasifik√°cie text√∫r s vyu≈æit√≠m zhlukovania.  

Let me help explain textures and their analysis based on the provided lecture materials. I'll break this down systematically:

1. Texture Characteristics and Definition:
- Texture refers to the surface characteristics defined by lay, surface roughness, and waviness
- In image processing, texture provides information about the spatial arrangement of colors or intensities in an image
- Texture gradient is an important concept where texture appears finer as distance increases (like looking at grass from different distances)

2. Main Approaches to Texture Analysis:

A. Structural Approach:
- Views texture as a set of primitive texels (texture elements) in regular or repeated relationships
- Focuses on identifying basic texture patterns and their arrangements

B. Fourier Approach:
- Analyzes local Fourier transforms of the image
- Provides information about:
  - Spatial frequencies contributions
  - Dominant orientations in the texture
- Uses power spectrum analysis with:
  - Ring filters for frequency band contributions
  - Wedge filters for edge orientation information

C. Statistical Approach:
- Characterizes texture using statistical measures from grayscale intensities
- Key method: Co-occurrence Matrices
  - Process:
    1. Separate intensity into discrete levels
    2. Choose displacement vector
    3. Count pixel pairs with specific gray levels
    4. Normalize the matrix
  - Six important characteristics can be derived from these matrices (though specific characteristics aren't listed in the document)

3. Practical Applications:

A. Texture Segmentation:
- Uses texture characteristics to detect regions and contours
- Can employ clustering techniques for classification
- Example shown using graycomatrix function for analyzing horizontal pixel relationships

4. Advanced Concepts:

- Texture Gradient: Used for surface orientation estimation
- Scale Dependency: Texture appearance changes with viewing distance
- Edge Density and Direction: Used as initial steps in texture analysis
  - Counts edge pixels in fixed regions
  - Analyzes edge directions for texture characterization

The document mentions classification using clustering but doesn't specifically detail Laws' texture masks, though these are typically used for texture feature extraction.

For texture classification using clustering, the document shows:
1. Feature selection from texture characteristics
2. Manual parameter setting
3. Cluster center determination
4. Winner-takes-all clustering approach

Would you like me to elaborate on any of these aspects or focus on a specific part of texture analysis?

17 OTAZKA Vysvetlite pojmy ohniskov√° vzdialenos≈• objekt√≠vu, clonov√© ƒç√≠slo, r√Ωchlos≈• uz√°vierky, hƒ∫bka ostrosti. Ako vpl√Ωva na hƒ∫bku ostrosti nastavenie clony a ohniskov√° vzdialenos≈• objekt√≠vu? Ak√Ω vplyv m√° na obraz pou≈æitie objekt√≠vov s r√¥znou ohniskovou vzdialenos≈•ou. ƒåo predstavuje spr√°vna expoz√≠cia sn√≠mky, ƒço n√°s pri spr√°vnej expoz√≠cii obmedzuje? 

Na z√°klade predn√°≈°ky "Basics of Photography" a ot√°zky, ktor√° pokr√Ωva z√°kladn√© pojmy a ich vz≈•ah k fotografii, pon√∫kam podrobn√© vysvetlenie:

---

### **1. Ohniskov√° vzdialenos≈• objekt√≠vu**
Ohniskov√° vzdialenos≈• je miera schopnosti optick√©ho syst√©mu s√∫streƒèova≈• (konvergova≈•) alebo rozptyƒæova≈• (divergova≈•) svetlo. Vyjadruje sa v milimetroch (mm) a urƒçuje, ak√Ω uhol z√°beru (zorn√© pole) objekt√≠v zachyt√°va. 
- **Krat≈°ia ohniskov√° vzdialenos≈• (≈°irokouhl√Ω objekt√≠v)**: V√§ƒç≈°√≠ uhol z√°beru, lep≈°ia hƒ∫bka ostrosti, vhodn√Ω na krajiny alebo architekt√∫ru. 
- **Dlh≈°ia ohniskov√° vzdialenos≈• (teleobjekt√≠v)**: U≈æ≈°√≠ uhol z√°beru, zv√§ƒç≈°enie vzdialen√Ωch objektov, plytk√° hƒ∫bka ostrosti, vhodn√Ω na ≈°port alebo portr√©ty.

---

### **2. Clonov√© ƒç√≠slo**
Clonov√© ƒç√≠slo (f/ƒç√≠slo) predstavuje pomer ohniskovej vzdialenosti k priemeru vstupnej pupily (clony). 
- **Ni≈æ≈°ie f/ƒç√≠slo** (v√§ƒç≈°√≠ otvor): Viac svetla, plyt≈°ia hƒ∫bka ostrosti, pou≈æiteƒæn√© pri slabom osvetlen√≠.
- **Vy≈°≈°ie f/ƒç√≠slo** (men≈°√≠ otvor): Menej svetla, v√§ƒç≈°ia hƒ∫bka ostrosti, vhodn√© na krajiny alebo makrofotografiu.

---

### **3. R√Ωchlos≈• uz√°vierky**
R√Ωchlos≈• uz√°vierky urƒçuje, ako dlho zostane svetlo dopada≈• na senzor alebo film. 
- **Kr√°tka r√Ωchlos≈• (napr. 1/1000 s)**: Zachyt√°va r√Ωchly pohyb, minimalizuje rozmazanie.
- **Dlh√° r√Ωchlos≈• (napr. 1/10 s)**: Zachyt√°va pohyb vo forme rozmazania, vhodn√° na kreat√≠vne efekty (napr. rozmazanie vody).

---

### **4. Hƒ∫bka ostrosti (DOF)**
Hƒ∫bka ostrosti je rozsah vzdialenost√≠, kde s√∫ objekty v z√°bere ostr√©. 
- **Faktory ovplyv≈àuj√∫ce hƒ∫bku ostrosti**:
  - **Clonov√© ƒç√≠slo**: V√§ƒç≈°ie clonov√© ƒç√≠slo (men≈°ia clona) zvy≈°uje hƒ∫bku ostrosti.
  - **Ohniskov√° vzdialenos≈•**: Dlh≈°ia ohniskov√° vzdialenos≈• zni≈æuje hƒ∫bku ostrosti.
  - **Vzdialenos≈• od objektu**: ƒå√≠m bli≈æ≈°ie je objekt, t√Ωm je hƒ∫bka ostrosti men≈°ia.

---

### **5. Vplyv objekt√≠vov s r√¥znou ohniskovou vzdialenos≈•ou na obraz**
- **≈†irokouhl√© objekt√≠vy**: Zv√Ωraz≈àuj√∫ vzdialenosti medzi objektmi, poskytuj√∫ v√§ƒç≈°iu hƒ∫bku ostrosti, vhodn√© na krajiny alebo interi√©ry.
- **Teleobjekt√≠vy**: Komprimuj√∫ vzdialenosti, vytv√°raj√∫ il√∫ziu bli≈æ≈°ieho vz≈•ahu medzi objektmi, vhodn√© na portr√©ty alebo detailn√© sn√≠mky.

---

### **6. Spr√°vna expoz√≠cia sn√≠mky**
Spr√°vna expoz√≠cia znamen√°, ≈æe sn√≠mka obsahuje dostatok detailov v tie≈àoch aj vo svetl√Ωch ƒçastiach bez straty inform√°ci√≠. Dosahuje sa kombin√°ciou:
- **Clonov√©ho ƒç√≠sla**, 
- **R√Ωchlosti uz√°vierky**, 
- **ISO** (citlivos≈• senzoru na svetlo).

**Obmedzenia pri expoz√≠cii**:
- **Clona**: Obmedzen√° vlastnos≈•ami objekt√≠vu (maxim√°lne a minim√°lne f/ƒç√≠slo).
- **Uz√°vierka**: Pri dlh√Ωch ƒçasoch je potrebn√Ω stat√≠v, aby sa predi≈°lo rozmazaniu.
- **ISO**: Vy≈°≈°ie ISO prid√°va ≈°um.

---

### **Z√°ver**
Fotografick√© techniky, ako pr√°ca s ohniskovou vzdialenos≈•ou, clonov√Ωm ƒç√≠slom a r√Ωchlos≈•ou uz√°vierky, z√°sadne ovplyv≈àuj√∫ vzhƒæad sn√≠mky. Hlb≈°ie pochopenie t√Ωchto faktorov je kƒæ√∫ƒçom k vytv√°raniu kreat√≠vnych a technicky spr√°vnych fotografi√≠.

18 OTAZKA ƒåo ovplyv≈àuje ISO nastavenie, ak√Ω m√° vplyv na ≈°um v obraze? ƒåo to je dynamick√Ω rozsah senzoru, ako sa l√≠≈°i od ƒæudsk√©ho oka. ƒåo je to HDR composite. ƒåo to je focus stacking? Ako mo≈æno redukova≈• ≈°um pri fotografovan√≠ statick√Ωch objektov? ƒåo ovplyv≈àuje mno≈æstvo detailov zachytiteƒæn√Ωch digit√°lnou kamerou? (acutance vs. resolution) ƒåo je to chromatick√° aber√°cia a preƒço vznik√°?

Na z√°klade ot√°zky poskytujem detailn√© vysvetlenie k jednotliv√Ωm bodom:

---

### **1. ISO nastavenie a jeho vplyv na ≈°um**
- **ISO** (International Standards Organization) urƒçuje citlivos≈• senzora na svetlo. 
  - **Ni≈æ≈°ie ISO (napr. 100‚Äì200)**: Men≈°ia citlivos≈•, menej ≈°umu, vhodn√© pri dobrom osvetlen√≠.
  - **Vy≈°≈°ie ISO (napr. 1600 a viac)**: V√§ƒç≈°ia citlivos≈•, viac ≈°umu, vhodn√© pri slabom osvetlen√≠.
- **≈†um** vznik√°, keƒè sa zosil≈àuje sign√°l zo senzora, priƒçom sa zosil≈àuj√∫ aj ne≈æiad√∫ce elektronick√© poruchy (noise).

---

### **2. Dynamick√Ω rozsah senzoru a jeho rozdiel od ƒæudsk√©ho oka**
- **Dynamick√Ω rozsah senzoru**: Rozsah medzi najtmav≈°√≠m a najsvetlej≈°√≠m bodom, ktor√© senzor dok√°≈æe zachyti≈• bez straty detailov.
  - **Be≈æn√Ω rozsah senzoru**: ~10‚Äì15 expoziƒçn√Ωch krokov (stops).
  - **ƒΩudsk√© oko**: M√° ≈°ir≈°√≠ dynamick√Ω rozsah (~20 stops) a dok√°≈æe sa dynamicky prisp√¥sobi≈• r√¥znym √∫rovniam jasu, ƒço fotoapar√°ty nedok√°≈æu bez dodatoƒçn√Ωch techn√≠k (napr. HDR).

---

### **3. HDR composite**
- **HDR (High Dynamic Range) composite**: Technika sp√°jania viacer√Ωch sn√≠mok s r√¥znymi expoz√≠ciami (napr. podexponovan√°, spr√°vne exponovan√°, preexponovan√°). 
  - V√Ωsledkom je obraz s v√§ƒç≈°√≠m dynamick√Ωm rozsahom, kde s√∫ zachovan√© detaily v tie≈àoch aj svetl√Ωch oblastiach.
  - Pou≈æ√≠va sa na sc√©ny s vysok√Ωm kontrastom, ako napr√≠klad pri fotografovan√≠ krajiny za jasn√©ho slneƒçn√©ho d≈àa.

---

### **4. Focus stacking**
- **Focus stacking**: Digit√°lna technika kombinuj√∫ca viac sn√≠mok s r√¥znymi zaostren√Ωmi rovinami (hlbok√° ostros≈• ka≈æd√©ho z√°beru na in√∫ ƒças≈• sc√©ny).
  - V√Ωsledkom je obraz s v√§ƒç≈°ou hƒ∫bkou ostrosti ne≈æ ak√Ωkoƒævek jednotliv√Ω zdrojov√Ω obr√°zok.
  - Pou≈æ√≠va sa pri makrofotografii alebo pri fotografovan√≠ produktov, kde je d√¥le≈æit√° ostr√° detailnos≈• v celom z√°bere.

---

### **5. Redukcia ≈°umu pri fotografovan√≠ statick√Ωch objektov**
- **Redukcia ≈°umu**:
  - Pou≈æitie **ni≈æ≈°ieho ISO** (napr. ISO 100‚Äì200).
  - **Dlh≈°ie expoziƒçn√© ƒçasy** s pou≈æit√≠m stat√≠vu.
  - Pou≈æitie techniky **image stacking**: Viacer√© sn√≠mky s√∫ spriemerovan√©, ƒço redukuje n√°hodn√Ω ≈°um.
  - **Post-procesing**: Softv√©rov√© n√°stroje ako Adobe Lightroom na redukciu ≈°umu.

---

### **6. Mno≈æstvo detailov zachytiteƒæn√Ωch kamerou (acutance vs. resolution)**
- **Resolution (rozl√≠≈°enie)**: Poƒçet zachyten√Ωch pixelov, teda schopnos≈• odl√≠≈°i≈• bl√≠zko umiestnen√© detaily. Vy≈°≈°ie rozl√≠≈°enie znamen√° viac pixelov a jemnej≈°ie detaily.
- **Acutance (ostros≈•)**: Subjekt√≠vne vn√≠manie ostrosti obrazu, ovplyvnen√© r√Ωchlos≈•ou prechodu medzi svetlom a tie≈àom. V√§ƒç≈°√≠ kontrast hr√°n m√¥≈æe zv√Ω≈°i≈• vn√≠man√∫ ostros≈•, aj keƒè rozl√≠≈°enie ost√°va rovnak√©.

---

### **7. Chromatick√° aber√°cia**
- **Defin√≠cia**: Optick√° chyba objekt√≠vu sp√¥soben√° t√Ωm, ≈æe r√¥zne vlnov√© dƒ∫≈æky svetla (farby) sa l√°mu pod odli≈°n√Ωmi uhlami.
- **Preƒço vznik√°**: Svetlo prech√°dzaj√∫ce cez ≈°o≈°ovku sa rozklad√° na jednotliv√© farby (podobne ako pri prizme). Tieto farby sa nezhroma≈æƒèuj√∫ do jedn√©ho bodu, ƒço vedie k farebn√Ωm okrajom (napr. purpurov√© alebo zelen√© fringing).
- **Ako ju zn√≠≈æi≈•**:
  - Pou≈æitie objekt√≠vov s **asf√©rick√Ωmi ≈°o≈°ovkami** alebo ≈°peci√°lnymi n√≠zko-dispersn√Ωmi materi√°lmi.
  - **Clonenie**: Zn√≠≈æenie otvoru clony m√¥≈æe redukova≈• chromatick√∫ aber√°ciu.
  - **Post-procesing**: Softv√©r na √∫pravu fotografi√≠ (napr. Lightroom alebo Photoshop) umo≈æ≈àuje odstr√°nenie chromatickej aber√°cie.

---

### **Z√°ver**
Pochopenie t√Ωchto faktorov a techn√≠k umo≈æ≈àuje fotografom efekt√≠vne ovl√°da≈• kvalitu sn√≠mok, minimalizova≈• chyby a maximalizova≈• technick√∫ i umeleck√∫ hodnotu v√Ωsledn√Ωch fotografi√≠.



